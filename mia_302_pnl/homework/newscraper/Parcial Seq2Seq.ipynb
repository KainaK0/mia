{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72260fc4f7ef4b60",
   "metadata": {},
   "source": [
    "### Método Seq2Seg\n",
    "Para este caso vamos a implementar un modelo generador de titulos de las noticias, vamos a entrenar con las noticias scrapeadas del diario gestion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135a1615c9cf724",
   "metadata": {},
   "source": [
    "### Instalación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3739a60d443f0082",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T02:45:02.665494Z",
     "start_time": "2025-06-01T02:44:47.010648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.12/site-packages (2.7.0+cpu)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.12/site-packages (0.22.0+cpu)\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.12/site-packages (2.7.0+cpu)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.12/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch) (78.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.12/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.12/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.12/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.12/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install pandas nltk tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de1f1cd34735a966",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T02:45:07.406043Z",
     "start_time": "2025-06-01T02:45:07.391748Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c46aa90f949e653",
   "metadata": {},
   "source": [
    "### Implementación del Modelo Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b90d110d8b52817",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T17:55:30.007488Z",
     "start_time": "2025-06-01T17:55:29.979738Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 0. Parámetros principales (ajústalos según tu GPU/CPU)\n",
    "# -------------------------------------------------\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Tamaños de vocabulario máximos (puedes variar)\n",
    "MAX_VOCAB_SRC = 20000    # Para tokens de \"summit\"\n",
    "MAX_VOCAB_TGT = 5000     # Para tokens de \"title\"\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "\n",
    "# Máxima longitud de secuencias (ajusta según histogramas de longitud)\n",
    "MAX_LEN_SRC = 200\n",
    "MAX_LEN_TGT = 20\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 15\n",
    "TEACHER_FORCING_RATIO = 0.5  # Probabilidad de usar teacher forcing durante entrenamiento\n",
    "\n",
    "# Tokens especiales\n",
    "PAD_TOKEN = \"<pad>\"\n",
    "SOS_TOKEN = \"<sos>\"\n",
    "EOS_TOKEN = \"<eos>\"\n",
    "UNK_TOKEN = \"<unk>\"\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1. Funciones de limpieza y tokenización\n",
    "# -------------------------------------------------\n",
    "nltk.download('stopwords', quiet=True)\n",
    "SPANISH_STOP = set(stopwords.words(\"spanish\"))\n",
    "\n",
    "def limpiar_texto(texto: str) -> str:\n",
    "    \"\"\"\n",
    "    - Minúsculas.\n",
    "    - Elimina caracteres que no sean letras (incluidas tildes y ñ) ni espacios ni dígitos.\n",
    "    - Sustituye múltiples espacios por uno solo.\n",
    "    - Remueve stopwords.\n",
    "    \"\"\"\n",
    "    texto = texto.lower()\n",
    "    texto = re.sub(r\"[^a-záéíóúñü0-9\\s]\", \" \", texto)\n",
    "    texto = re.sub(r\"\\s+\", \" \", texto).strip()\n",
    "    tokens = texto.split()\n",
    "    tokens = [t for t in tokens if t not in SPANISH_STOP]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def tokenizar(texto: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Simplemente divide por espacios (ya que limpiamos antes),\n",
    "    retornando una lista de tokens.\n",
    "    \"\"\"\n",
    "    return texto.split()\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2. Leer JSON y preparar pares (entrada, salida)\n",
    "# -------------------------------------------------\n",
    "def cargar_dataset_json(ruta_json: str):\n",
    "    \"\"\"\n",
    "    Lee un archivo JSON con estructura de lista de objetos:\n",
    "      [\n",
    "        {\n",
    "          \"title\": \"...\",\n",
    "          \"category\": \"...\",\n",
    "          \"summit\": \"...\",\n",
    "          \"description\": \"...\",\n",
    "          \"date\": \"...\",\n",
    "          \"autor\": \"...\",\n",
    "          \"tags\": \"...\",\n",
    "          \"url\": \"...\"\n",
    "        },\n",
    "        ...\n",
    "      ]\n",
    "    Extrae 'summit' como fuente y 'title' como objetivo, los limpia y tokeniza.\n",
    "    Devuelve dos listas de listas de tokens:\n",
    "      - documentos_src: lista de listas de tokens tokenizados de 'summit'\n",
    "      - documentos_tgt: lista de listas de tokens tokenizados de 'title'\n",
    "    \"\"\"\n",
    "    with open(ruta_json, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    documentos_src = []\n",
    "    documentos_tgt = []\n",
    "\n",
    "    for item in tqdm(data, desc=\"Leyendo y limpiando JSON\"):\n",
    "        summit = item.get(\"summit\", \"\")\n",
    "        title  = item.get(\"title\", \"\")\n",
    "\n",
    "        if not summit or not title:\n",
    "            continue\n",
    "\n",
    "        summit_limpio = limpiar_texto(str(summit))\n",
    "        title_limpio  = limpiar_texto(str(title))\n",
    "\n",
    "        tokens_src = tokenizar(summit_limpio)\n",
    "        tokens_tgt = tokenizar(title_limpio)\n",
    "\n",
    "        if len(tokens_src) == 0 or len(tokens_tgt) == 0:\n",
    "            continue  # descartamos si quedó vacío\n",
    "\n",
    "        documentos_src.append(tokens_src)\n",
    "        documentos_tgt.append(tokens_tgt)\n",
    "\n",
    "    return documentos_src, documentos_tgt\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3. Construir vocabularios (SRC y TGT)\n",
    "# -------------------------------------------------\n",
    "from collections import Counter\n",
    "\n",
    "class Vocab:\n",
    "    \"\"\"\n",
    "    Clase para almacenar el mapeo token->índice e índice->token,\n",
    "    y convertir listas de tokens a listas de índices (y viceversa).\n",
    "    \"\"\"\n",
    "    def __init__(self, max_size: int):\n",
    "        self.counter = Counter()\n",
    "        self.max_size = max_size\n",
    "        # Diccionarios finales\n",
    "        self.stoi = {}\n",
    "        self.itos = {}\n",
    "\n",
    "    def construir(self, lista_de_textos: list[list[str]]):\n",
    "        # 1) Contar todos los tokens\n",
    "        for texto in lista_de_textos:\n",
    "            self.counter.update(texto)\n",
    "\n",
    "        # 2) Tomar los N tokens más frecuentes (menos los especiales)\n",
    "        vocab_tokens = [tok for tok, _ in self.counter.most_common(self.max_size)]\n",
    "        # 3) Agregar tokens especiales al inicio\n",
    "        tokens_finales = [PAD_TOKEN, SOS_TOKEN, EOS_TOKEN, UNK_TOKEN] + vocab_tokens\n",
    "\n",
    "        # 4) Construir mapeos\n",
    "        for idx, tok in enumerate(tokens_finales):\n",
    "            self.stoi[tok] = idx\n",
    "            self.itos[idx] = tok\n",
    "\n",
    "    def token2idx(self, token: str) -> int:\n",
    "        return self.stoi.get(token, self.stoi[UNK_TOKEN])\n",
    "\n",
    "    def idx2token(self, idx: int) -> str:\n",
    "        return self.itos.get(idx, UNK_TOKEN)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.stoi)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 4. Dataset personalizado y DataLoader\n",
    "# -------------------------------------------------\n",
    "class TitulosDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset que recibe dos listas de listas de tokens:\n",
    "      - documentos_src: [[tok1, tok2, ...], [...], ...]\n",
    "      - documentos_tgt: [[tok1, tok2, ...], [...], ...]\n",
    "    También recibe los vocabularios construidos (Vocab src y Vocab tgt).\n",
    "    Devuelve:\n",
    "      - src_tensor: [longitud_src] con índices\n",
    "      - tgt_tensor: [longitud_tgt] con índices (incluye <sos> ... <eos>)\n",
    "    \"\"\"\n",
    "    def __init__(self, documentos_src, documentos_tgt, vocab_src: Vocab, vocab_tgt: Vocab):\n",
    "        assert len(documentos_src) == len(documentos_tgt)\n",
    "        self.docs_src = documentos_src\n",
    "        self.docs_tgt = documentos_tgt\n",
    "        self.vocab_src = vocab_src\n",
    "        self.vocab_tgt = vocab_tgt\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.docs_src)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens_src = self.docs_src[idx]\n",
    "        tokens_tgt = self.docs_tgt[idx]\n",
    "\n",
    "        # Convertir tokens a índices\n",
    "        src_indices = [ self.vocab_src.token2idx(tok) for tok in tokens_src ]\n",
    "        # Para el target, agregamos SOS al inicio y EOS al final\n",
    "        tgt_indices = [ self.vocab_tgt.token2idx(SOS_TOKEN) ] + \\\n",
    "                      [ self.vocab_tgt.token2idx(tok) for tok in tokens_tgt ] + \\\n",
    "                      [ self.vocab_tgt.token2idx(EOS_TOKEN) ]\n",
    "\n",
    "        return src_indices, tgt_indices\n",
    "\n",
    "# Los siguientes vocab_src y vocab_tgt se definirán en main,\n",
    "# pero pad_collate los usará como variables globales:\n",
    "vocab_src = None\n",
    "vocab_tgt = None\n",
    "\n",
    "def pad_collate(batch):\n",
    "    \"\"\"\n",
    "    Función para collate_fn de DataLoader:\n",
    "    Recibe un batch = lista de tuplas (src_indices, tgt_indices).\n",
    "    Retorna:\n",
    "      - src_tensor_padded: (batch_size, MAX_LEN_SRC)\n",
    "      - tgt_input_padded: (batch_size, MAX_LEN_TGT)  [para decoder_input]\n",
    "      - tgt_output_padded: (batch_size, MAX_LEN_TGT) [para calcular loss]\n",
    "    \"\"\"\n",
    "    batch_src, batch_tgt = zip(*batch)\n",
    "\n",
    "    # 1) Para cada secuencia src, recortamos/pad a MAX_LEN_SRC\n",
    "    src_padded = []\n",
    "    for seq in batch_src:\n",
    "        if len(seq) > MAX_LEN_SRC:\n",
    "            seq = seq[:MAX_LEN_SRC]\n",
    "        # padding a la derecha con índice de PAD_TOKEN\n",
    "        pad_len = MAX_LEN_SRC - len(seq)\n",
    "        seq = seq + [vocab_src.token2idx(PAD_TOKEN)] * pad_len\n",
    "        src_padded.append(seq)\n",
    "\n",
    "    # 2) Para cada secuencia tgt, recortamos/pad a MAX_LEN_TGT\n",
    "    #    Para generar input y output del decoder:\n",
    "    #    - decoder_input: todo hasta penúltimo token\n",
    "    #    - decoder_output: todo desde el token 1 (sin <sos>) \n",
    "    dec_in_padded = []\n",
    "    dec_out_padded = []\n",
    "    for seq in batch_tgt:\n",
    "        if len(seq) > MAX_LEN_TGT:\n",
    "            seq = seq[:MAX_LEN_TGT]\n",
    "        pad_len = MAX_LEN_TGT - len(seq)\n",
    "        seq = seq + [vocab_tgt.token2idx(PAD_TOKEN)] * pad_len\n",
    "\n",
    "        # Decoder input es toda la secuencia tal cual (incluye <sos> ... <eos> ... <pad>)\n",
    "        dec_input = seq\n",
    "        # Decoder output es el mismo seq desplazado a la izquierda, con PAD al final\n",
    "        dec_output = seq[1:] + [vocab_tgt.token2idx(PAD_TOKEN)]\n",
    "        dec_in_padded.append(dec_input)\n",
    "        dec_out_padded.append(dec_output)\n",
    "\n",
    "    # Convertir a tensores largos (LongTensor)\n",
    "    src_tensor = torch.LongTensor(src_padded)\n",
    "    tgt_input_tensor = torch.LongTensor(dec_in_padded)\n",
    "    tgt_output_tensor = torch.LongTensor(dec_out_padded)\n",
    "\n",
    "    return src_tensor.to(DEVICE), tgt_input_tensor.to(DEVICE), tgt_output_tensor.to(DEVICE)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 5. Definir modelo Seq2Seq con atención (Bahdanau)\n",
    "# -------------------------------------------------\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=vocab_src.token2idx(PAD_TOKEN))\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=False)\n",
    "\n",
    "    def forward(self, src_seq):\n",
    "        # src_seq: (batch_size, max_len_src)\n",
    "        embedded = self.embedding(src_seq)  # (batch, max_len_src, embed_dim)\n",
    "        outputs, (h, c) = self.lstm(embedded)\n",
    "        # outputs: (batch, max_len_src, hidden_dim)\n",
    "        # h, c: (1, batch, hidden_dim)\n",
    "        return outputs, (h, c)\n",
    "\n",
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        # Para Bahdanau: score = v^T tanh(W1 * dec_hidden + W2 * enc_output)\n",
    "        self.W1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.W2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.V  = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, dec_hidden, enc_outputs):\n",
    "        \"\"\"\n",
    "        dec_hidden: (batch, hidden_dim) → estado oculto actual del Decoder (t)\n",
    "        enc_outputs: (batch, max_len_src, hidden_dim) → salidas del Encoder en todos los timesteps\n",
    "        Queremos calcular las “atenciones” a cada posición del encoder para este timestep.\n",
    "\n",
    "        Pasos:\n",
    "        1) dec_hidden expandido a (batch, max_len_src, hidden_dim)\n",
    "        2) score = V^T tanh(W1(enc_outputs) + W2(dec_hidden_expandido))\n",
    "        3) attention_weights = softmax(score, dim=1)  → (batch, max_len_src, 1)\n",
    "        4) context_vector = suma(attention_weights * enc_outputs, dim=1)  → (batch, hidden_dim)\n",
    "        \"\"\"\n",
    "        batch_size, max_len_src, _ = enc_outputs.size()\n",
    "        dec_hidden_exp = dec_hidden.unsqueeze(1).repeat(1, max_len_src, 1)  # (batch, max_len_src, hidden_dim)\n",
    "\n",
    "        energy = torch.tanh(self.W1(enc_outputs) + self.W2(dec_hidden_exp))  # (batch, max_len_src, hidden_dim)\n",
    "        score = self.V(energy)  # (batch, max_len_src, 1)\n",
    "\n",
    "        attention_weights = torch.softmax(score, dim=1)  # (batch, max_len_src, 1)\n",
    "        context_vector = torch.sum(attention_weights * enc_outputs, dim=1)  # (batch, hidden_dim)\n",
    "\n",
    "        return context_vector, attention_weights  # (batch, hidden_dim), (batch, max_len_src, 1)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=vocab_tgt.token2idx(PAD_TOKEN))\n",
    "        self.lstm = nn.LSTM(embed_dim + hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.attention = BahdanauAttention(hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)  # salida sobre vocabulario\n",
    "\n",
    "    def forward(self, dec_input_token, dec_hidden, dec_cell, enc_outputs):\n",
    "        \"\"\"\n",
    "        dec_input_token: (batch, 1) → índice del token actual a predecir\n",
    "        dec_hidden: (1, batch, hidden_dim)\n",
    "        dec_cell:   (1, batch, hidden_dim)\n",
    "        enc_outputs: (batch, max_len_src, hidden_dim)\n",
    "\n",
    "        Devuelve:\n",
    "          - logits: (batch, vocab_size) → logits sin softmax para este timestep\n",
    "          - new_hidden, new_cell: nuevos estados (1, batch, hidden_dim)\n",
    "          - attn_weights: (batch, max_len_src, 1)\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(dec_input_token)  # (batch, 1, embed_dim)\n",
    "        dec_hidden_2d = dec_hidden.squeeze(0)       # (batch, hidden_dim)\n",
    "        context_vector, attn_weights = self.attention(dec_hidden_2d, enc_outputs)\n",
    "        embedded_2d = embedded.squeeze(1)           # (batch, embed_dim)\n",
    "\n",
    "        lstm_input = torch.cat([embedded_2d, context_vector], dim=-1).unsqueeze(1)  # (batch,1,embed+hidden)\n",
    "        output, (new_hidden, new_cell) = self.lstm(lstm_input, (dec_hidden, dec_cell))\n",
    "        output = output.squeeze(1)  # (batch, hidden_dim)\n",
    "        logits = self.fc(output)    # (batch, vocab_size)\n",
    "\n",
    "        return logits, new_hidden, new_cell, attn_weights\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 6. Bucle de entrenamiento\n",
    "# -------------------------------------------------\n",
    "def entrenar_epoch(\n",
    "        encoder: Encoder,\n",
    "        decoder: Decoder,\n",
    "        dataloader: DataLoader,\n",
    "        encoder_optimizer,\n",
    "        decoder_optimizer,\n",
    "        criterion\n",
    "):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for src_batch, tgt_in_batch, tgt_out_batch in tqdm(dataloader, desc=\"Entrenando\"):\n",
    "        batch_size = src_batch.size(0)\n",
    "\n",
    "        # A) Borra gradientes\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        # B) Forward pass del encoder\n",
    "        enc_outputs, (h, c) = encoder(src_batch)\n",
    "\n",
    "        # C) Preparar inputs para el decoder\n",
    "        dec_hidden = h\n",
    "        dec_cell   = c\n",
    "        dec_input_token = torch.LongTensor([vocab_tgt.token2idx(SOS_TOKEN)] * batch_size).unsqueeze(1).to(DEVICE)\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        # D) Iterar sobre cada timestep del target\n",
    "        for t in range(MAX_LEN_TGT):\n",
    "            logits, dec_hidden, dec_cell, _ = decoder(\n",
    "                dec_input_token, dec_hidden, dec_cell, enc_outputs\n",
    "            )\n",
    "            ground_truth = tgt_out_batch[:, t]  # (batch,)\n",
    "            loss_t = criterion(logits, ground_truth)\n",
    "            loss += loss_t\n",
    "\n",
    "            use_teacher = True if random.random() < TEACHER_FORCING_RATIO else False\n",
    "            if use_teacher:\n",
    "                dec_input_token = tgt_in_batch[:, t].unsqueeze(1)\n",
    "            else:\n",
    "                pred_token = logits.argmax(dim=1)\n",
    "                dec_input_token = pred_token.unsqueeze(1)\n",
    "\n",
    "        # E) Backpropagation\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() / MAX_LEN_TGT  # promedio por palabra\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 7. Función de inferencia para generar título\n",
    "# -------------------------------------------------\n",
    "def generar_titulo(\n",
    "        texto_src: str,\n",
    "        encoder: Encoder,\n",
    "        decoder: Decoder,\n",
    "        tokenizer_src_vocab: Vocab,\n",
    "        tokenizer_tgt_vocab: Vocab,\n",
    "        max_len_src: int,\n",
    "        max_len_tgt: int\n",
    ") -> str:\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    # 1) Limpiar y tokenizar\n",
    "    texto_limpio = limpiar_texto(texto_src)\n",
    "    tokens = tokenizar(texto_limpio)\n",
    "\n",
    "    # 2) Tokens → índices\n",
    "    indices = [ tokenizer_src_vocab.token2idx(tok) for tok in tokens ]\n",
    "    if len(indices) > max_len_src:\n",
    "        indices = indices[:max_len_src]\n",
    "    else:\n",
    "        pad_len = max_len_src - len(indices)\n",
    "        indices = indices + [ tokenizer_src_vocab.token2idx(PAD_TOKEN) ] * pad_len\n",
    "\n",
    "    src_tensor = torch.LongTensor(indices).unsqueeze(0).to(DEVICE)  # (1, max_len_src)\n",
    "\n",
    "    # 3) Encoder forward\n",
    "    with torch.no_grad():\n",
    "        enc_outputs, (dec_hidden, dec_cell) = encoder(src_tensor)\n",
    "\n",
    "    # 4) Inicializar dec_input_token = <sos>\n",
    "    dec_input_token = torch.LongTensor([ tokenizer_tgt_vocab.token2idx(SOS_TOKEN) ]).unsqueeze(1).to(DEVICE)\n",
    "\n",
    "    resultado_tokens = []\n",
    "\n",
    "    # 5) Iterar timesteps en el decoder\n",
    "    for _ in range(max_len_tgt):\n",
    "        with torch.no_grad():\n",
    "            logits, dec_hidden, dec_cell, _ = decoder(dec_input_token, dec_hidden, dec_cell, enc_outputs)\n",
    "        pred_token_idx = logits.argmax(dim=1).item()  # escalar\n",
    "\n",
    "        if pred_token_idx == tokenizer_tgt_vocab.token2idx(EOS_TOKEN) or \\\n",
    "                pred_token_idx == tokenizer_tgt_vocab.token2idx(PAD_TOKEN):\n",
    "            break\n",
    "\n",
    "        pred_token = tokenizer_tgt_vocab.idx2token(pred_token_idx)\n",
    "        resultado_tokens.append(pred_token)\n",
    "\n",
    "        dec_input_token = torch.LongTensor([pred_token_idx]).unsqueeze(1).to(DEVICE)\n",
    "\n",
    "    return \" \".join(resultado_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd57727888f3ac18",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32e4b444c3d3ca51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T18:09:28.211101Z",
     "start_time": "2025-06-01T17:55:41.843634Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Leyendo y limpiando JSON: 100%|██████████| 3761/3761 [00:00<00:00, 54516.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Construyendo vocabularios...\n",
      "Tamaño vocab_SRC: 12241\n",
      "Tamaño vocab_TGT: 5004\n",
      "\n",
      "Iniciando entrenamiento:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 59/59 [00:36<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15  →  Loss promedio: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 59/59 [00:38<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15  →  Loss promedio: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 59/59 [00:38<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15  →  Loss promedio: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 59/59 [00:38<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15  →  Loss promedio: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 59/59 [00:39<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15  →  Loss promedio: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 59/59 [00:38<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15  →  Loss promedio: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 59/59 [00:39<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15  →  Loss promedio: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 59/59 [00:39<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15  →  Loss promedio: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 59/59 [00:39<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15  →  Loss promedio: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 59/59 [00:38<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15  →  Loss promedio: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 59/59 [00:38<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15  →  Loss promedio: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 59/59 [00:38<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15  →  Loss promedio: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando: 100%|██████████| 59/59 [00:38<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15  →  Loss promedio: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------\n",
    "# 8. Pipeline completo adaptado a JSON\n",
    "# -------------------------------------------------\n",
    "# 1) Cargar datos desde JSON\n",
    "ruta_json = \"gestionspider4.json\"  # Ajusta el nombre si tu JSON es distinto\n",
    "docs_src, docs_tgt = cargar_dataset_json(ruta_json)\n",
    "\n",
    "# 2) Construir vocabularios\n",
    "print(\"\\nConstruyendo vocabularios...\")\n",
    "vocab_src = Vocab(MAX_VOCAB_SRC)\n",
    "vocab_src.construir(docs_src)\n",
    "\n",
    "vocab_tgt = Vocab(MAX_VOCAB_TGT)\n",
    "vocab_tgt.construir(docs_tgt)\n",
    "\n",
    "print(f\"Tamaño vocab_SRC: {len(vocab_src)}\")\n",
    "print(f\"Tamaño vocab_TGT: {len(vocab_tgt)}\")\n",
    "\n",
    "# 3) Crear Dataset y DataLoader\n",
    "dataset = TitulosDataset(docs_src, docs_tgt, vocab_src, vocab_tgt)\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=pad_collate\n",
    ")\n",
    "\n",
    "# 4) Instanciar modelos\n",
    "encoder = Encoder(len(vocab_src), EMBEDDING_DIM, HIDDEN_DIM).to(DEVICE)\n",
    "decoder = Decoder(len(vocab_tgt), EMBEDDING_DIM, HIDDEN_DIM).to(DEVICE)\n",
    "\n",
    "# 5) Definir optimizadores y función de pérdida\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=1e-3)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=vocab_tgt.token2idx(PAD_TOKEN))\n",
    "\n",
    "# 6) Entrenamiento\n",
    "print(\"\\nIniciando entrenamiento:\")\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    loss_epoch = entrenar_epoch(\n",
    "        encoder, decoder, dataloader,\n",
    "        encoder_optimizer, decoder_optimizer, criterion\n",
    "    )\n",
    "    print(f\"Epoch {epoch}/{EPOCHS}  →  Loss promedio: {loss_epoch:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af239a5a6b4bdf",
   "metadata": {},
   "source": [
    "### Validando Modelo - Generando títulos a las noticias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e601e8a74db37d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T18:09:28.388948Z",
     "start_time": "2025-06-01T18:09:28.213628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generando títulos de ejemplo (primeros 5 del dataset):\n",
      "\n",
      "Detalle (recortado): autoridad portuaria señala mayoría operadores puertos concesionados interior evalúa acogerse nueva ley permite prorrogar plazos contratos...\n",
      "  Título real   : apn puerto callao espera us 2 300 millones adicionales extensión concesiones\n",
      "  Título generado: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "\n",
      "Detalle (recortado): tendencia lineal mayo pues inició mes s 3 66 luego repuntó s 3 69...\n",
      "  Título real   : dólar s 3 62 quiénes convendría comprar\n",
      "  Título generado: <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "\n",
      "Detalle (recortado): municipalidad victoria evalúa nuevo espacio comercial modo sincere ingresos negocios relación alquiler percibido comuna detalles entrevista alcalde rubén cano...\n",
      "  Título real   : luego tiendas parque cánepa próxima concesión bajo lupa victoria\n",
      "  Título generado: <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "\n",
      "Detalle (recortado): asociación gremios productores agrarios perú agap detalló golpe empleo interés inversores...\n",
      "  Título real   : agro alcanzada criminalidad minería cultivos exportación afectados\n",
      "  Título generado: <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "\n",
      "Detalle (recortado): detrás sólido comportamiento ahorro personas condiciones macroeconómicas actuales refiere scotiabank...\n",
      "  Título real   : ahorro crece generando ganancias peruanos\n",
      "  Título generado: <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7) Probar inferencia en algunos ejemplos aleatorios del dataset\n",
    "print(\"\\nGenerando títulos de ejemplo (primeros 5 del dataset):\\n\")\n",
    "for i in range(5):\n",
    "    resumen = \" \".join(docs_src[i])  # reconstruyo el texto preprocesado\n",
    "    titulo_real = \" \".join(docs_tgt[i])\n",
    "    titulo_gen = generar_titulo(\n",
    "        texto_src=resumen,\n",
    "        encoder=encoder,\n",
    "        decoder=decoder,\n",
    "        tokenizer_src_vocab=vocab_src,\n",
    "        tokenizer_tgt_vocab=vocab_tgt,\n",
    "        max_len_src=MAX_LEN_SRC,\n",
    "        max_len_tgt=MAX_LEN_TGT\n",
    "    )\n",
    "    print(f\"Detalle (recortado): {' '.join(docs_src[i][:30])}...\")\n",
    "    print(f\"  Título real   : {titulo_real}\")\n",
    "    print(f\"  Título generado: {titulo_gen}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
