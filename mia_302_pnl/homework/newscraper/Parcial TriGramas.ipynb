{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Generador de Noticias usando Trigramas a partir de noticias extraídas por web scraping del diario Gestión",
   "id": "5974440b427c4fbb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Instalación de Librerías",
   "id": "d4928e4d4f73069f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-01T02:13:17.265748Z",
     "start_time": "2025-06-01T02:13:11.369836Z"
    }
   },
   "source": "!pip install pandas nltk tqdm",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\programdata\\miniconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: nltk in c:\\programdata\\miniconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\miniconda3\\lib\\site-packages (4.66.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\miniconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\miniconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: click in c:\\programdata\\miniconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\miniconda3\\lib\\site-packages (from nltk) (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\miniconda3\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\miniconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\programdata\\miniconda3\\lib\\site-packages\\vboxapi-1.0-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Implementación Trigramas",
   "id": "d11c40a99da44854"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T16:13:12.768731Z",
     "start_time": "2025-06-01T16:13:12.754715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 0. Descargar recursos NLTK necesarios (solo la primera vez)\n",
    "# --------------------------------------------------\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1. Función para limpiar y tokenizar cada texto\n",
    "# --------------------------------------------------\n",
    "def limpiar_y_tokenizar(texto: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    1) Convierte a minúsculas.\n",
    "    2) Elimina caracteres que no sean letras, dígitos o espacios.\n",
    "    3) Tokeniza usando nltk.word_tokenize (divide en palabras y puntuación por separado).\n",
    "    4) Filtra tokens que no contengan al menos una letra.\n",
    "    Devuelve la lista de tokens “limpios”.\n",
    "    \"\"\"\n",
    "    # 1) Convertir a minúsculas\n",
    "    texto = texto.lower()\n",
    "    # 2) Eliminar todo lo que no sea letra, número o espacio\n",
    "    texto = re.sub(r\"[^a-záéíóúñü0-9\\s]\", \" \", texto)\n",
    "    # 3) Tokenizar\n",
    "    tokens = word_tokenize(texto, language=\"spanish\")\n",
    "    # 4) Filtrar tokens muy cortos o que no tengan ninguna letra\n",
    "    tokens = [tok for tok in tokens if re.search(r\"[a-záéíóúñü]\", tok)]\n",
    "    return tokens\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2. Leer el JSON y construir lista de documentos tokenizados\n",
    "# --------------------------------------------------\n",
    "def cargar_y_tokenizar_json(ruta_json: str) -> list[list[str]]:\n",
    "    \"\"\"\n",
    "    Lee un archivo JSON con la siguiente estructura (lista de objetos):\n",
    "      [\n",
    "        {\n",
    "          \"title\": \"...\",\n",
    "          \"category\": \"...\",\n",
    "          \"summit\": \"...\",\n",
    "          \"description\": \"...\",\n",
    "          \"date\": \"...\",\n",
    "          \"autor\": \"...\",\n",
    "          \"tags\": \"['Seguro Social', 'Estados Unidos']\",\n",
    "          \"url\": \"...\"\n",
    "        },\n",
    "        { ... },\n",
    "        ...\n",
    "      ]\n",
    "    Extrae el campo 'description' de cada objeto, lo limpia y tokeniza.\n",
    "    Devuelve una lista de listas de tokens (cada lista es un documento tokenizado).\n",
    "    \"\"\"\n",
    "    # Cargar el JSON completo. Asumimos que es un array de objetos.\n",
    "    with open(ruta_json, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    documentos = []\n",
    "    for item in tqdm(data, desc=\"Tokenizando descripciones\"):\n",
    "        # Extraer descripción; si no existe o está vacío, la saltamos\n",
    "        desc = item.get(\"description\", \"\")\n",
    "        # Convertir a str por si viniera nulo\n",
    "        desc = str(desc)\n",
    "        # Limpiar y tokenizar\n",
    "        tokens = limpiar_y_tokenizar(desc)\n",
    "        # Solo añadimos si tenemos al menos 3 tokens (para formar trigramas)\n",
    "        if len(tokens) >= 3:\n",
    "            documentos.append(tokens)\n",
    "\n",
    "    return documentos\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3. Construir el diccionario de trigramas y sus frecuencias\n",
    "# --------------------------------------------------\n",
    "def construir_trigramas(documentos: list[list[str]]) -> Counter:\n",
    "    \"\"\"\n",
    "    Recorre cada documento (lista de tokens) y extrae todos los trigramas\n",
    "    consecutivos (palabra_i, palabra_{i+1}, palabra_{i+2}).\n",
    "    Devuelve un Counter que mapea cada trigram (tupla de 3 tokens) a su frecuencia total.\n",
    "    \"\"\"\n",
    "    contador_trigramas = Counter()\n",
    "    for doc in documentos:\n",
    "        for i in range(len(doc) - 2):\n",
    "            trigram = (doc[i], doc[i + 1], doc[i + 2])\n",
    "            contador_trigramas[trigram] += 1\n",
    "    return contador_trigramas\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4. Extraer los trigramas más frecuentes\n",
    "# --------------------------------------------------\n",
    "def obtener_trigramas_top(contador: Counter, top_n: int = 20) -> list[tuple[tuple[str, str, str], int]]:\n",
    "    \"\"\"\n",
    "    Dado un Counter de trigramas, devuelve los `top_n` (trigrama, frecuencia)\n",
    "    ordenados de mayor a menor frecuencia.\n",
    "    \"\"\"\n",
    "    return contador.most_common(top_n)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 5. Construir estructuras auxiliares para generación de texto\n",
    "# --------------------------------------------------\n",
    "def construir_modelo_trigramas(contador: Counter) -> dict[tuple[str, str], dict[str, int]]:\n",
    "    \"\"\"\n",
    "    A partir del Counter global de trigramas:\n",
    "    Creamos un diccionario que para cada bigram (palabra_i, palabra_{i+1})\n",
    "    tenga mapeado un diccionario con {palabra_{i+2}: frecuencia}.\n",
    "    Estructura final: \n",
    "      modelo[(w1, w2)] = { w3a: freq1, w3b: freq2, … }\n",
    "    \"\"\"\n",
    "    modelo = defaultdict(lambda: defaultdict(int))\n",
    "    for (w1, w2, w3), freq in contador.items():\n",
    "        modelo[(w1, w2)][w3] = freq\n",
    "    return modelo\n",
    "\n",
    "def muestrear_siguiente_palabra(probs: dict[str, int]) -> str:\n",
    "    \"\"\"\n",
    "    Dado un diccionario de frecuencias {palabra: cuenta}, convertimos en lista de\n",
    "    probabilidades y muestreamos una palabra aleatoria de acuerdo a su peso.\n",
    "    \"\"\"\n",
    "    total = sum(probs.values())\n",
    "    palabras = []\n",
    "    pesos = []\n",
    "    for palabra, cuenta in probs.items():\n",
    "        palabras.append(palabra)\n",
    "        pesos.append(cuenta / total)\n",
    "    return random.choices(palabras, weights=pesos, k=1)[0]\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 6. Generador de texto basado en trigramas\n",
    "# --------------------------------------------------\n",
    "def generar_texto_trigramas(modelo: dict[tuple[str, str], dict[str, int]],\n",
    "                            inicio: tuple[str, str],\n",
    "                            longitud: int = 50) -> str:\n",
    "    \"\"\"\n",
    "    1) Partimos de un bigram (w1, w2) que debe existir en las claves del modelo.\n",
    "    2) Vamos generando palabra a palabra: la siguiente w_{i+2} se muestrea con base en \n",
    "       modelo[(w1, w2)].\n",
    "    3) La ventana de bigram “avanza” un paso: (w2, w_{i+2}), y seguimos así hasta llegar\n",
    "       a `longitud` palabras generadas (excluyendo las dos iniciales).\n",
    "    4) Devolvemos el texto generado concatenando con espacios.\n",
    "    \"\"\"\n",
    "    w1, w2 = inicio\n",
    "    if (w1, w2) not in modelo:\n",
    "        raise ValueError(f\"El par inicial {inicio} no está en el vocabulario de bigramas.\")\n",
    "\n",
    "    resultado = [w1, w2]\n",
    "    for _ in range(longitud - 2):\n",
    "        siguiente_dict = modelo.get((w1, w2), None)\n",
    "        if not siguiente_dict:\n",
    "            break  # Si no hay continuación, detenemos la generación\n",
    "        w3 = muestrear_siguiente_palabra(siguiente_dict)\n",
    "        resultado.append(w3)\n",
    "        # Avanzamos la ventana\n",
    "        w1, w2 = w2, w3\n",
    "\n",
    "    return \" \".join(resultado)"
   ],
   "id": "c8e4f6d06dbdc216",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Generarador de Noticias",
   "id": "92c369aaf22817d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T16:13:21.223884Z",
     "start_time": "2025-06-01T16:13:19.059383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cambiamos la ruta para apuntar a un JSON en lugar de CSV\n",
    "RUTA_JSON = \"gestionspider5.json\"  # Ajusta este nombre a tu archivo real\n",
    "TOP_N = 20          # Cantidad de trigramas más frecuentes a mostrar\n",
    "LONGITUD_GEN = 50   # Número total de tokens que queremos generar (incluye dos palabras iniciales)\n",
    "\n",
    "# 1) Leer y tokenizar desde JSON (campo \"description\")\n",
    "documentos = cargar_y_tokenizar_json(RUTA_JSON)\n",
    "\n",
    "# 2) Contar trigramas en todo el corpus\n",
    "contador_tri = construir_trigramas(documentos)\n",
    "\n",
    "# 3) Identeficar los TOP_N trigramas más comunes\n",
    "top_trigramas = obtener_trigramas_top(contador_tri, TOP_N)\n",
    "\n",
    "# 4) Construir el modelo auxiliar (bigram → {tercera palabra: frecuencia})\n",
    "modelo_tri = construir_modelo_trigramas(contador_tri)\n",
    "\n",
    "# 5) Elegir uno de los trigramas más frecuentes como “semilla” (bigram)\n",
    "trigram_ejemplo, _ = top_trigramas[0]  # usamos el trigram más frecuente\n",
    "bigram_inicial = (trigram_ejemplo[0], trigram_ejemplo[1])\n",
    "print(f\"\\nUsando el bigram inicial: {bigram_inicial}\\n\")\n",
    "\n",
    "# 6) Generar texto de ejemplo\n",
    "texto_generado = generar_texto_trigramas(modelo_tri, bigram_inicial, longitud=LONGITUD_GEN)\n",
    "print(\"Texto de ejemplo generado (primeras 50 palabras aprox.):\\n\")\n",
    "print(texto_generado, \"\\n\")"
   ],
   "id": "96d8bc73e6e99afa",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizando descripciones: 100%|██████████| 1308/1308 [00:01<00:00, 929.16it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usando el bigram inicial: ('a', 'través')\n",
      "\n",
      "Texto de ejemplo generado (primeras 50 palabras aprox.):\n",
      "\n",
      "a través del abastecimiento en línea con la primera semana de cuatro nuevos proyectos para este jueves de abril la variación de las gratificaciones es inconstitucional pero usted sabe los ciudadanos cómo pueden actuar dentro de la región que a partir de las tres últimas plataformas del nuevo centro de \n",
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Combinaciones más frecuentes y su interpretación",
   "id": "b9e5bb201408facb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T16:13:26.240821Z",
     "start_time": "2025-06-01T16:13:26.235198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"\\nLos {TOP_N} trigramas más frecuentes y sus frecuencias:\\n\")\n",
    "for trigram, freq in top_trigramas:\n",
    "    print(f\"  {' '.join(trigram):<40}  →  {freq}\")"
   ],
   "id": "e2195a22e0abe58a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Los 20 trigramas más frecuentes y sus frecuencias:\n",
      "\n",
      "  a través de                               →  274\n",
      "  uno de los                                →  215\n",
      "  el ministerio de                          →  209\n",
      "  de estados unidos                         →  204\n",
      "  de la república                           →  192\n",
      "  en el país                                →  192\n",
      "  en el mercado                             →  164\n",
      "  de us millones                            →  156\n",
      "  en el perú                                →  155\n",
      "  por lo que                                →  153\n",
      "  de acuerdo con                            →  147\n",
      "  la comisión de                            →  140\n",
      "  de la empresa                             →  138\n",
      "  por su parte                              →  135\n",
      "  de millones de                            →  129\n",
      "  en los últimos                            →  126\n",
      "  una de las                                →  125\n",
      "  en el caso                                →  124\n",
      "  de este año                               →  117\n",
      "  el de los                                 →  114\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Interpretación",
   "id": "23cd43fdb408531e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Top 1: frase “a través de” (274), frase muy común en redacción periodística para indicar el medio o canal por el cual algo ocurre, su alta frecuencia (274) sugiere que el corpus incluye numerosas notas en las que se cita qué “vehículo” o “medio” se utiliza para llevar a cabo alguna acción (por ejemplo, programas, acuerdos, pagos, transmisiones).\n",
    "\n",
    "Top 2: frase “uno de los” (215), señala que, con frecuencia, las noticias sacan a relucir rankings, listas o comparaciones (“uno de los más relevantes”).\n",
    "\n",
    "Top 3: frase “el ministerio de” (209), muy común cuando se menciona la actuación o comunicado de una cartera estatal, indica cobertura de políticas, normas o reportes oficiales."
   ],
   "id": "a845c08c904ec649"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
