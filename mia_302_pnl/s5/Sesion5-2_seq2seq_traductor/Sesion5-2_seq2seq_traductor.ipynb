{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo seq2seq. Construcción de un traductor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Basado en F. Collet, [Character-level recurrent sequence-to-sequence model](https://keras.io/examples/nlp/lstm_seq2seq/)\n",
    "2. [Write a Sequence to Sequence (seq2seq) Model](https://docs.chainer.org/en/stable/examples/seq2seq.html)\n",
    "3. Ilya Sutskever et al. (Google),[Sequence to Sequence Learning\n",
    "with Neural Network](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contenido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Importa módulos](#Importa-módulos)\n",
    "* [Configuración](#Configuración)\n",
    "* [Prepara los datos](#Prepara-los-datos)\n",
    "* [Construye el modelo](#Construye-el-modelo)\n",
    "* [Entrena el modelo](#Entrena-el-modelo)\n",
    "* [Modelo de inferencia](#Modelo-de-inferencia)\n",
    "* [Prueba del modelo](#Prueba-del-modelo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo de secuencia a secuencia (seq2seq)  es un modelo de aprendizaje que convierte una secuencia de entrada en una secuencia de salida. \n",
    "\n",
    "En este contexto, la secuencia es una lista de símbolos, correspondiente a las palabras en una oración. \n",
    "\n",
    "El modelo seq2seq ha logrado un gran éxito en campos como la traducción automática, los sistemas de diálogo, la respuesta a preguntas y el resumen de texto. \n",
    "\n",
    "Todas estas tareas pueden considerarse como la tarea de aprender un modelo que convierte una secuencia de entrada en una secuencia de salida.\n",
    "\n",
    "La imagen muestra la arquitectura general del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/seq2seq.png\" width=\"500\" height=\"300\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">Arquitectura del modelo seq2seq</p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Fuente: [Write a Sequence to Sequence (seq2seq) Model](https://docs.chainer.org/en/stable/examples/seq2seq.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo consta escencialmente de las siguientes capas.\n",
    "\n",
    "1. Capa de incrustación de codificador\n",
    "2. Capa recurrente del codificador\n",
    "3. Capa de incrustación de decodificador\n",
    "4. Capa recurrente del decodificador\n",
    "5. Capa de salida del decodificador\n",
    "\n",
    "Veámos la implementación en t.keras propuesta por F. Collet, [Character-level recurrent sequence-to-sequence model]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importa módulos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarga los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede descargar los de [Tab-delimited Bilingual Sentence Pairs](http://www.manythings.org/anki/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 # tamño de los lotes para entrenamiento\n",
    "epochs = 100 # Número de epochs\n",
    "latent_dim = 256 # dimensión del espacio latente para el encoder\n",
    "num_samples = 10000\n",
    "# path del archivo\n",
    "data_path = \"spa-eng/spa.txt\" # 124548 lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepara los datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: Go.- T: Ve.\n",
      "I: Go.- T: Vete.\n",
      "I: Go.- T: Vaya.\n",
      "I: Go.- T: Váyase.\n",
      "I: Hi.- T: Hola.\n",
      "I: Run!- T: ¡Corre!\n",
      "I: Run!- T: ¡Corran!\n",
      "I: Run!- T: ¡Huye!\n",
      "I: Run!- T: ¡Corra!\n",
      "I: Run!- T: ¡Corred!\n",
      "I: Run.- T: Corra.\n",
      "I: Run.- T: Corred.\n",
      "I: Who?- T: ¿Quién?\n",
      "I: Wow!- T: ¡Órale!\n",
      "I: Duck!- T: ¡Inclínate!\n",
      "I: Fire!- T: ¡Fuego!\n",
      "I: Fire!- T: ¡Incendio!\n",
      "I: Fire!- T: ¡Disparad!\n",
      "I: Help!- T: ¡Ayuda!\n",
      "I: Help!- T: ¡Socorro! ¡Auxilio!\n",
      "Number of samples: 10000\n",
      "Number of unique input tokens: 69\n",
      "Number of unique output tokens: 84\n",
      "Max sequence length for inputs: 16\n",
      "Max sequence length for outputs: 47\n",
      "preparando datos...\n",
      "....\n",
      "datos preparados\n"
     ]
    }
   ],
   "source": [
    "# Vectoriza los datos\n",
    "#\n",
    "i=0\n",
    "targe_text= ''\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\") # 124548 lines\n",
    "\n",
    "for line in lines[:min(num_samples,len(lines)-1)]:\n",
    "    input_text, target_text, _ = line.split(\"\\t\")\n",
    "    if (i<20):\n",
    "        print(\"I: \" + input_text + \"- T: \" + target_text)\n",
    "    # Usaremos \"tab\" como el  caracter de inicio (start sequence)\n",
    "    # para los targets, y \"\\n\" como el caracter de fin de secuencia \"end sequence\"\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"\n",
    "    # sube las líneas a  las listas\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "  \n",
    "    # completa los conjuntos de caracteres si es necesario\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "    i=i+1\n",
    "\n",
    "# Convierte los dos conjuntos de caracteres\n",
    "# en dos listas ordenadas\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))  \n",
    "# calcule el número de tokens (caracteres) en ambos lados\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "# calcula la máxima longitud de las secuencias en cada lado\n",
    "max_encoder_seq_length = max([len(text) for text in input_texts])\n",
    "max_decoder_seq_length = max([len(text) for text in target_texts])\n",
    "\n",
    "print(\"Number of samples:\", len(input_texts))\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
    "print(\"preparando datos...\")\n",
    "# crea diccionarios de tokens\n",
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "# crea los tensores 1-hot para el encoder y el decoder\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\")\n",
    "\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
    "\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
    "\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
    "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
    "\n",
    "print (\"....\\ndatos preparados\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construye el modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define una secuencia de entrada y la procesa\n",
    "encoder_inputs = Input(shape = (None, num_encoder_tokens))\n",
    "\n",
    "# capa recurrente del encoder\n",
    "encoder = LSTM(latent_dim, return_state = True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# Descartamos las salidas (encoder_outputs)\n",
    "# solamente se conserva las memoria de  corto (state_h) y \n",
    "# largo plazo(state_c)\n",
    "encoder_states = [state_h, state_c]\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuramos el decoder, usando 'encoder_states' como estado inicial\n",
    "decoder_inputs = Input(shape= (None, num_decoder_tokens))\n",
    "\n",
    "# capa recurrente del decoder\n",
    "# Configuramos nuestro decodificador para devolver secuencias de salida completas,\n",
    "# y también para devolver estados internos. No usamos los\n",
    "# estados retornados en el modelo de entrenamiento, pero los usaremos en inferencia.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _,_ = decoder_lstm(decoder_inputs,initial_state = encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydot\n",
      "  Downloading pydot-4.0.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pyparsing>=3.0.9 in /home/kainak0/gitProjects/mia/mia_302_pnl/.venv/lib/python3.12/site-packages (from pydot) (3.2.3)\n",
      "Downloading pydot-4.0.0-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: pydot\n",
      "Successfully installed pydot-4.0.0\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Downloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: graphviz\n",
      "Successfully installed graphviz-0.20.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot\n",
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate parameters:\n",
    "\n",
    "lstm Layer:\n",
    "        The LSTM layer has three gates: input gate, forget gate, and output gate.\n",
    "        The number of parameters in each gate depends on the input size, hidden state size, and bias terms.\n",
    "        The formula to calculate the number of parameters in each gate is (input_size + hidden_size) * hidden_size + hidden_size.\n",
    "        In this case, you've mentioned an output shape of (None, 256) for the LSTM layer, which indicates a hidden state size of 256.\n",
    "        The input size is not explicitly mentioned, but you've mentioned that it's connected to 'input_1[0][0]', which would have an input size of 69.\n",
    "        So, for each gate in the lstm layer: (69 + 256) * 256 + 256 = 333824 parameters.\n",
    "\n",
    "lstm_1 Layer:\n",
    "        This LSTM layer seems to be a sequence-to-sequence style LSTM since it has an output shape of (None, None, 256).\n",
    "        The number of parameters in each gate is calculated the same way as for the previous lstm layer.\n",
    "        The input size for the gates of this lstm_1 layer is 256, as the previous lstm layer's output size is connected to it.\n",
    "        For each gate in the lstm_1 layer: (256 + 256) * 256 + 256 = 349184 parameters.\n",
    "\n",
    "dense Layer:\n",
    "        The dense layer is a standard fully connected layer.\n",
    "        The number of parameters is calculated by (input_size * output_size) + output_size.\n",
    "        In this case, the input size is 256 (output size of the lstm_1 layer), and the output size is 84.\n",
    "        So, for the dense layer: (256 * 84) + 84 = 21588 parameters.\n",
    "\n",
    "Overall, the total number of parameters in your model can be calculated by summing up the parameters from the lstm layer, the lstm_1 layer, and the dense layer: 333824 + 349184 + 21588 = 704596 parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">69</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">333,824</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">349,184</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],       │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]        │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">21,588</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m69\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     │    \u001b[38;5;34m333,824\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │    \u001b[38;5;34m349,184\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],       │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]        │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)  │     \u001b[38;5;34m21,588\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">704,596</span> (2.69 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m704,596\u001b[0m (2.69 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">704,596</span> (2.69 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m704,596\u001b[0m (2.69 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "plot_model(model, to_file='../Imagenes/s2s.png', \n",
    "           show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrena el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "125/125 [==============================] - 78s 549ms/step - loss: 1.3912 - accuracy: 0.6931 - val_loss: 1.2173 - val_accuracy: 0.6635\n",
      "Epoch 2/100\n",
      "125/125 [==============================] - 61s 486ms/step - loss: 0.9613 - accuracy: 0.7358 - val_loss: 1.0431 - val_accuracy: 0.7125\n",
      "Epoch 3/100\n",
      "125/125 [==============================] - 64s 514ms/step - loss: 0.8237 - accuracy: 0.7705 - val_loss: 0.9138 - val_accuracy: 0.7375\n",
      "Epoch 4/100\n",
      "125/125 [==============================] - 68s 542ms/step - loss: 0.7340 - accuracy: 0.7869 - val_loss: 0.8399 - val_accuracy: 0.7525\n",
      "Epoch 5/100\n",
      "125/125 [==============================] - 68s 543ms/step - loss: 0.6790 - accuracy: 0.7995 - val_loss: 0.7907 - val_accuracy: 0.7652\n",
      "Epoch 6/100\n",
      "125/125 [==============================] - 66s 531ms/step - loss: 0.6397 - accuracy: 0.8093 - val_loss: 0.7524 - val_accuracy: 0.7755\n",
      "Epoch 7/100\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 0.7032 - accuracy: 0.8005 - val_loss: 0.7959 - val_accuracy: 0.7642\n",
      "Epoch 8/100\n",
      "125/125 [==============================] - 67s 534ms/step - loss: 0.6326 - accuracy: 0.8117 - val_loss: 0.7382 - val_accuracy: 0.7789\n",
      "Epoch 9/100\n",
      "125/125 [==============================] - 66s 530ms/step - loss: 0.5967 - accuracy: 0.8206 - val_loss: 0.7109 - val_accuracy: 0.7871\n",
      "Epoch 10/100\n",
      "125/125 [==============================] - 65s 521ms/step - loss: 0.5764 - accuracy: 0.8264 - val_loss: 0.6942 - val_accuracy: 0.7913\n",
      "Epoch 11/100\n",
      "125/125 [==============================] - 64s 515ms/step - loss: 0.5596 - accuracy: 0.8313 - val_loss: 0.6782 - val_accuracy: 0.7959\n",
      "Epoch 12/100\n",
      "125/125 [==============================] - 63s 508ms/step - loss: 0.5443 - accuracy: 0.8358 - val_loss: 0.6680 - val_accuracy: 0.7984\n",
      "Epoch 13/100\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 0.5297 - accuracy: 0.8400 - val_loss: 0.6581 - val_accuracy: 0.8021\n",
      "Epoch 14/100\n",
      "125/125 [==============================] - 69s 551ms/step - loss: 0.5163 - accuracy: 0.8441 - val_loss: 0.6470 - val_accuracy: 0.8042\n",
      "Epoch 15/100\n",
      "125/125 [==============================] - 66s 530ms/step - loss: 0.5037 - accuracy: 0.8479 - val_loss: 0.6361 - val_accuracy: 0.8084\n",
      "Epoch 16/100\n",
      "125/125 [==============================] - 64s 516ms/step - loss: 0.4898 - accuracy: 0.8520 - val_loss: 0.6293 - val_accuracy: 0.8107\n",
      "Epoch 17/100\n",
      "125/125 [==============================] - 63s 503ms/step - loss: 0.4779 - accuracy: 0.8557 - val_loss: 0.6209 - val_accuracy: 0.8147\n",
      "Epoch 18/100\n",
      "125/125 [==============================] - 62s 500ms/step - loss: 0.4654 - accuracy: 0.8594 - val_loss: 0.6138 - val_accuracy: 0.8166\n",
      "Epoch 19/100\n",
      "125/125 [==============================] - 64s 510ms/step - loss: 0.4542 - accuracy: 0.8630 - val_loss: 0.6072 - val_accuracy: 0.8180\n",
      "Epoch 20/100\n",
      "125/125 [==============================] - 61s 489ms/step - loss: 0.4420 - accuracy: 0.8666 - val_loss: 0.6001 - val_accuracy: 0.8206\n",
      "Epoch 21/100\n",
      "125/125 [==============================] - 60s 478ms/step - loss: 0.4306 - accuracy: 0.8698 - val_loss: 0.5911 - val_accuracy: 0.8235\n",
      "Epoch 22/100\n",
      "125/125 [==============================] - 59s 472ms/step - loss: 0.4193 - accuracy: 0.8732 - val_loss: 0.5904 - val_accuracy: 0.8240\n",
      "Epoch 23/100\n",
      "125/125 [==============================] - 59s 474ms/step - loss: 0.4090 - accuracy: 0.8762 - val_loss: 0.5847 - val_accuracy: 0.8246\n",
      "Epoch 24/100\n",
      "125/125 [==============================] - 60s 477ms/step - loss: 0.3972 - accuracy: 0.8796 - val_loss: 0.5779 - val_accuracy: 0.8278\n",
      "Epoch 25/100\n",
      "125/125 [==============================] - 61s 488ms/step - loss: 0.3876 - accuracy: 0.8827 - val_loss: 0.5763 - val_accuracy: 0.8302\n",
      "Epoch 26/100\n",
      "125/125 [==============================] - 60s 478ms/step - loss: 0.3763 - accuracy: 0.8861 - val_loss: 0.5718 - val_accuracy: 0.8300\n",
      "Epoch 27/100\n",
      "125/125 [==============================] - 60s 476ms/step - loss: 0.3651 - accuracy: 0.8895 - val_loss: 0.5712 - val_accuracy: 0.8311\n",
      "Epoch 28/100\n",
      "125/125 [==============================] - 60s 477ms/step - loss: 0.3558 - accuracy: 0.8922 - val_loss: 0.5717 - val_accuracy: 0.8316\n",
      "Epoch 29/100\n",
      "125/125 [==============================] - 59s 474ms/step - loss: 0.3444 - accuracy: 0.8961 - val_loss: 0.5674 - val_accuracy: 0.8339\n",
      "Epoch 30/100\n",
      "125/125 [==============================] - 60s 483ms/step - loss: 0.3355 - accuracy: 0.8985 - val_loss: 0.5734 - val_accuracy: 0.8334\n",
      "Epoch 31/100\n",
      "125/125 [==============================] - 59s 476ms/step - loss: 0.3251 - accuracy: 0.9015 - val_loss: 0.5732 - val_accuracy: 0.8331\n",
      "Epoch 32/100\n",
      "125/125 [==============================] - 59s 475ms/step - loss: 0.3162 - accuracy: 0.9045 - val_loss: 0.5690 - val_accuracy: 0.8356\n",
      "Epoch 33/100\n",
      "125/125 [==============================] - 59s 476ms/step - loss: 0.3060 - accuracy: 0.9075 - val_loss: 0.5723 - val_accuracy: 0.8350\n",
      "Epoch 34/100\n",
      "125/125 [==============================] - 59s 476ms/step - loss: 0.2963 - accuracy: 0.9105 - val_loss: 0.5723 - val_accuracy: 0.8367\n",
      "Epoch 35/100\n",
      "125/125 [==============================] - 61s 486ms/step - loss: 0.2873 - accuracy: 0.9132 - val_loss: 0.5763 - val_accuracy: 0.8361\n",
      "Epoch 36/100\n",
      "125/125 [==============================] - 60s 480ms/step - loss: 0.2790 - accuracy: 0.9156 - val_loss: 0.5781 - val_accuracy: 0.8354\n",
      "Epoch 37/100\n",
      "125/125 [==============================] - 59s 475ms/step - loss: 0.2685 - accuracy: 0.9185 - val_loss: 0.5856 - val_accuracy: 0.8344\n",
      "Epoch 38/100\n",
      "125/125 [==============================] - 61s 487ms/step - loss: 0.2602 - accuracy: 0.9212 - val_loss: 0.5827 - val_accuracy: 0.8362\n",
      "Epoch 39/100\n",
      "125/125 [==============================] - 60s 482ms/step - loss: 0.2510 - accuracy: 0.9239 - val_loss: 0.5901 - val_accuracy: 0.8361\n",
      "Epoch 40/100\n",
      "125/125 [==============================] - 59s 476ms/step - loss: 0.2434 - accuracy: 0.9262 - val_loss: 0.5970 - val_accuracy: 0.8360\n",
      "Epoch 41/100\n",
      "125/125 [==============================] - 60s 480ms/step - loss: 0.2355 - accuracy: 0.9285 - val_loss: 0.5993 - val_accuracy: 0.8361\n",
      "Epoch 42/100\n",
      "125/125 [==============================] - 60s 481ms/step - loss: 0.2271 - accuracy: 0.9311 - val_loss: 0.6005 - val_accuracy: 0.8361\n",
      "Epoch 43/100\n",
      "125/125 [==============================] - 59s 477ms/step - loss: 0.2191 - accuracy: 0.9337 - val_loss: 0.6139 - val_accuracy: 0.8367\n",
      "Epoch 44/100\n",
      "125/125 [==============================] - 60s 477ms/step - loss: 0.2120 - accuracy: 0.9357 - val_loss: 0.6117 - val_accuracy: 0.8351\n",
      "Epoch 45/100\n",
      "125/125 [==============================] - 60s 484ms/step - loss: 0.2032 - accuracy: 0.9386 - val_loss: 0.6299 - val_accuracy: 0.8351\n",
      "Epoch 46/100\n",
      "125/125 [==============================] - 61s 484ms/step - loss: 0.1968 - accuracy: 0.9403 - val_loss: 0.6312 - val_accuracy: 0.8348\n",
      "Epoch 47/100\n",
      "125/125 [==============================] - 61s 485ms/step - loss: 0.1891 - accuracy: 0.9429 - val_loss: 0.6311 - val_accuracy: 0.8352\n",
      "Epoch 48/100\n",
      "125/125 [==============================] - 60s 480ms/step - loss: 0.1825 - accuracy: 0.9446 - val_loss: 0.6417 - val_accuracy: 0.8356\n",
      "Epoch 49/100\n",
      "125/125 [==============================] - 59s 474ms/step - loss: 0.1761 - accuracy: 0.9470 - val_loss: 0.6555 - val_accuracy: 0.8336\n",
      "Epoch 50/100\n",
      "125/125 [==============================] - 59s 472ms/step - loss: 0.1710 - accuracy: 0.9482 - val_loss: 0.6570 - val_accuracy: 0.8345\n",
      "Epoch 51/100\n",
      "125/125 [==============================] - 60s 480ms/step - loss: 0.1647 - accuracy: 0.9502 - val_loss: 0.6624 - val_accuracy: 0.8357\n",
      "Epoch 52/100\n",
      "125/125 [==============================] - 60s 483ms/step - loss: 0.1570 - accuracy: 0.9527 - val_loss: 0.6752 - val_accuracy: 0.8339\n",
      "Epoch 53/100\n",
      "125/125 [==============================] - 60s 482ms/step - loss: 0.1510 - accuracy: 0.9546 - val_loss: 0.6810 - val_accuracy: 0.8341\n",
      "Epoch 54/100\n",
      "125/125 [==============================] - 61s 492ms/step - loss: 0.1466 - accuracy: 0.9558 - val_loss: 0.6934 - val_accuracy: 0.8347\n",
      "Epoch 55/100\n",
      "125/125 [==============================] - 60s 481ms/step - loss: 0.1419 - accuracy: 0.9572 - val_loss: 0.7001 - val_accuracy: 0.8337\n",
      "Epoch 56/100\n",
      "125/125 [==============================] - 60s 480ms/step - loss: 0.1360 - accuracy: 0.9590 - val_loss: 0.7105 - val_accuracy: 0.8326\n",
      "Epoch 57/100\n",
      "125/125 [==============================] - 59s 474ms/step - loss: 0.1313 - accuracy: 0.9607 - val_loss: 0.7210 - val_accuracy: 0.8325\n",
      "Epoch 58/100\n",
      "125/125 [==============================] - 62s 497ms/step - loss: 0.1256 - accuracy: 0.9622 - val_loss: 0.7279 - val_accuracy: 0.8333\n",
      "Epoch 59/100\n",
      "125/125 [==============================] - 69s 550ms/step - loss: 0.1216 - accuracy: 0.9635 - val_loss: 0.7406 - val_accuracy: 0.8318\n",
      "Epoch 60/100\n",
      "125/125 [==============================] - 66s 526ms/step - loss: 0.1159 - accuracy: 0.9653 - val_loss: 0.7390 - val_accuracy: 0.8323\n",
      "Epoch 61/100\n",
      "125/125 [==============================] - 63s 507ms/step - loss: 0.1137 - accuracy: 0.9657 - val_loss: 0.7592 - val_accuracy: 0.8316\n",
      "Epoch 62/100\n",
      "125/125 [==============================] - 62s 496ms/step - loss: 0.1109 - accuracy: 0.9665 - val_loss: 0.7624 - val_accuracy: 0.8323\n",
      "Epoch 63/100\n",
      "125/125 [==============================] - 62s 499ms/step - loss: 0.1062 - accuracy: 0.9679 - val_loss: 0.7729 - val_accuracy: 0.8324\n",
      "Epoch 64/100\n",
      "125/125 [==============================] - 66s 526ms/step - loss: 0.1023 - accuracy: 0.9692 - val_loss: 0.7782 - val_accuracy: 0.8322\n",
      "Epoch 65/100\n",
      "125/125 [==============================] - 64s 511ms/step - loss: 0.0989 - accuracy: 0.9704 - val_loss: 0.7898 - val_accuracy: 0.8319\n",
      "Epoch 66/100\n",
      "125/125 [==============================] - 64s 512ms/step - loss: 0.0959 - accuracy: 0.9713 - val_loss: 0.7982 - val_accuracy: 0.8312\n",
      "Epoch 67/100\n",
      "125/125 [==============================] - 63s 501ms/step - loss: 0.0899 - accuracy: 0.9733 - val_loss: 0.8046 - val_accuracy: 0.8315\n",
      "Epoch 68/100\n",
      "125/125 [==============================] - 66s 531ms/step - loss: 0.0873 - accuracy: 0.9742 - val_loss: 0.8123 - val_accuracy: 0.8304\n",
      "Epoch 69/100\n",
      "125/125 [==============================] - 62s 498ms/step - loss: 0.0842 - accuracy: 0.9750 - val_loss: 0.8279 - val_accuracy: 0.8301\n",
      "Epoch 70/100\n",
      "125/125 [==============================] - 63s 502ms/step - loss: 0.0823 - accuracy: 0.9753 - val_loss: 0.8332 - val_accuracy: 0.8310\n",
      "Epoch 71/100\n",
      "125/125 [==============================] - 65s 516ms/step - loss: 0.0811 - accuracy: 0.9756 - val_loss: 0.8484 - val_accuracy: 0.8311\n",
      "Epoch 72/100\n",
      "125/125 [==============================] - 66s 532ms/step - loss: 0.0779 - accuracy: 0.9766 - val_loss: 0.8477 - val_accuracy: 0.8314\n",
      "Epoch 73/100\n",
      "125/125 [==============================] - 66s 525ms/step - loss: 0.0750 - accuracy: 0.9774 - val_loss: 0.8606 - val_accuracy: 0.8310\n",
      "Epoch 74/100\n",
      "125/125 [==============================] - 65s 520ms/step - loss: 0.0734 - accuracy: 0.9780 - val_loss: 0.8668 - val_accuracy: 0.8307\n",
      "Epoch 75/100\n",
      "125/125 [==============================] - 64s 510ms/step - loss: 0.0708 - accuracy: 0.9787 - val_loss: 0.8761 - val_accuracy: 0.8300\n",
      "Epoch 76/100\n",
      "125/125 [==============================] - 62s 494ms/step - loss: 0.0699 - accuracy: 0.9788 - val_loss: 0.8831 - val_accuracy: 0.8299\n",
      "Epoch 77/100\n",
      "125/125 [==============================] - 62s 496ms/step - loss: 0.0667 - accuracy: 0.9798 - val_loss: 0.8908 - val_accuracy: 0.8309\n",
      "Epoch 78/100\n",
      "125/125 [==============================] - 63s 503ms/step - loss: 0.0647 - accuracy: 0.9806 - val_loss: 0.9010 - val_accuracy: 0.8300\n",
      "Epoch 79/100\n",
      "125/125 [==============================] - 61s 486ms/step - loss: 0.0633 - accuracy: 0.9808 - val_loss: 0.9051 - val_accuracy: 0.8298\n",
      "Epoch 80/100\n",
      "125/125 [==============================] - 60s 482ms/step - loss: 0.0613 - accuracy: 0.9817 - val_loss: 0.9136 - val_accuracy: 0.8299\n",
      "Epoch 81/100\n",
      "125/125 [==============================] - 61s 486ms/step - loss: 0.0598 - accuracy: 0.9819 - val_loss: 0.9261 - val_accuracy: 0.8298\n",
      "Epoch 82/100\n",
      "125/125 [==============================] - 60s 481ms/step - loss: 0.0590 - accuracy: 0.9824 - val_loss: 0.9251 - val_accuracy: 0.8300\n",
      "Epoch 83/100\n",
      "125/125 [==============================] - 60s 482ms/step - loss: 0.0579 - accuracy: 0.9823 - val_loss: 0.9389 - val_accuracy: 0.8296\n",
      "Epoch 84/100\n",
      "125/125 [==============================] - 61s 485ms/step - loss: 0.0560 - accuracy: 0.9830 - val_loss: 0.9386 - val_accuracy: 0.8301\n",
      "Epoch 85/100\n",
      "125/125 [==============================] - 61s 487ms/step - loss: 0.0534 - accuracy: 0.9837 - val_loss: 0.9436 - val_accuracy: 0.8313\n",
      "Epoch 86/100\n",
      "125/125 [==============================] - 61s 486ms/step - loss: 0.0529 - accuracy: 0.9840 - val_loss: 0.9607 - val_accuracy: 0.8281\n",
      "Epoch 87/100\n",
      "125/125 [==============================] - 61s 491ms/step - loss: 0.0527 - accuracy: 0.9839 - val_loss: 0.9665 - val_accuracy: 0.8301\n",
      "Epoch 88/100\n",
      "125/125 [==============================] - 61s 489ms/step - loss: 0.0527 - accuracy: 0.9838 - val_loss: 0.9709 - val_accuracy: 0.8291\n",
      "Epoch 89/100\n",
      "125/125 [==============================] - 60s 484ms/step - loss: 0.0506 - accuracy: 0.9842 - val_loss: 0.9686 - val_accuracy: 0.8306\n",
      "Epoch 90/100\n",
      "125/125 [==============================] - 61s 485ms/step - loss: 0.0485 - accuracy: 0.9850 - val_loss: 0.9700 - val_accuracy: 0.8291\n",
      "Epoch 91/100\n",
      "125/125 [==============================] - 60s 482ms/step - loss: 0.0480 - accuracy: 0.9852 - val_loss: 0.9850 - val_accuracy: 0.8297\n",
      "Epoch 92/100\n",
      "125/125 [==============================] - 61s 491ms/step - loss: 0.0472 - accuracy: 0.9854 - val_loss: 0.9866 - val_accuracy: 0.8296\n",
      "Epoch 93/100\n",
      "125/125 [==============================] - 60s 480ms/step - loss: 0.0452 - accuracy: 0.9860 - val_loss: 0.9917 - val_accuracy: 0.8308\n",
      "Epoch 94/100\n",
      "125/125 [==============================] - 60s 482ms/step - loss: 0.0455 - accuracy: 0.9858 - val_loss: 1.0127 - val_accuracy: 0.8285\n",
      "Epoch 95/100\n",
      "125/125 [==============================] - 59s 475ms/step - loss: 0.0455 - accuracy: 0.9857 - val_loss: 1.0162 - val_accuracy: 0.8297\n",
      "Epoch 96/100\n",
      "125/125 [==============================] - 60s 478ms/step - loss: 0.0453 - accuracy: 0.9857 - val_loss: 1.0174 - val_accuracy: 0.8294\n",
      "Epoch 97/100\n",
      "125/125 [==============================] - 61s 485ms/step - loss: 0.0461 - accuracy: 0.9854 - val_loss: 1.0167 - val_accuracy: 0.8299\n",
      "Epoch 98/100\n",
      "125/125 [==============================] - 60s 481ms/step - loss: 0.0443 - accuracy: 0.9859 - val_loss: 1.0286 - val_accuracy: 0.8295\n",
      "Epoch 99/100\n",
      "125/125 [==============================] - 60s 477ms/step - loss: 0.0431 - accuracy: 0.9865 - val_loss: 1.0270 - val_accuracy: 0.8294\n",
      "Epoch 100/100\n",
      "125/125 [==============================] - 60s 483ms/step - loss: 0.0423 - accuracy: 0.9865 - val_loss: 1.0350 - val_accuracy: 0.8286\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Saved_Models/s2s\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Saved_Models/s2s\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "model.save(\"../Saved_Models/s2s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de inferencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Codifica la entrada y recuperar el estado inicial del decodificador.\n",
    "2. Ejecuta un paso del decodificador con este estado inicial y un token de \"inicio de secuencia\" como objetivo. La salida será el próximo token de destino.\n",
    "3. Repite con el token de destino actual y los estados actuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "encoder_inputs = model.input[0]  # input_1\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = model.input[1]  # input_2\n",
    "decoder_state_input_h = Input(shape=(latent_dim,), name=\"input_3\")\n",
    "decoder_state_input_c = Input(shape=(latent_dim,), name=\"input_4\")\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_lstm = model.layers[3]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "\n",
    "decoder_dense = model.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
    ")\n",
    "\n",
    "# Reverse-lookup taken index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos generar oraciones decodificadas como tales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 1s 575ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "-\n",
      "Oración de entrada: Go.\n",
      "Oración decodificada: Vete.\n",
      "\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "-\n",
      "Oración de entrada: Go.\n",
      "Oración decodificada: Vete.\n",
      "\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 228ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "-\n",
      "Oración de entrada: Go.\n",
      "Oración decodificada: Vete.\n",
      "\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "-\n",
      "Oración de entrada: Go.\n",
      "Oración decodificada: Vete.\n",
      "\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "-\n",
      "Oración de entrada: Hi.\n",
      "Oración decodificada: Hola.\n",
      "\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "-\n",
      "Oración de entrada: Run!\n",
      "Oración decodificada: ¡Corre!\n",
      "\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 249ms/step\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "-\n",
      "Oración de entrada: Run!\n",
      "Oración decodificada: ¡Corre!\n",
      "\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 225ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "-\n",
      "Oración de entrada: Run!\n",
      "Oración decodificada: ¡Corre!\n",
      "\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "-\n",
      "Oración de entrada: Run!\n",
      "Oración decodificada: ¡Corre!\n",
      "\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 218ms/step\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 229ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "1/1 [==============================] - 0s 212ms/step\n",
      "-\n",
      "Oración de entrada: Run!\n",
      "Oración decodificada: ¡Corre!\n",
      "\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 207ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "-\n",
      "Oración de entrada: Run.\n",
      "Oración decodificada: Corre.\n",
      "\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 244ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "-\n",
      "Oración de entrada: Run.\n",
      "Oración decodificada: Corre.\n",
      "\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 207ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "-\n",
      "Oración de entrada: Who?\n",
      "Oración decodificada: ¿Quién?\n",
      "\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "1/1 [==============================] - 0s 242ms/step\n",
      "-\n",
      "Oración de entrada: Wow!\n",
      "Oración decodificada: ¡Órale!\n",
      "\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 229ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "-\n",
      "Oración de entrada: Duck!\n",
      "Oración decodificada: ¡Inclínate!\n",
      "\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 224ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 212ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "-\n",
      "Oración de entrada: Fire!\n",
      "Oración decodificada: ¡Incendio!\n",
      "\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "-\n",
      "Oración de entrada: Fire!\n",
      "Oración decodificada: ¡Incendio!\n",
      "\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "-\n",
      "Oración de entrada: Fire!\n",
      "Oración decodificada: ¡Incendio!\n",
      "\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 237ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "-\n",
      "Oración de entrada: Help!\n",
      "Oración decodificada: ¡Ayuda!\n",
      "\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "-\n",
      "Oración de entrada: Help!\n",
      "Oración decodificada: ¡Ayuda!\n",
      "\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "-\n",
      "Oración de entrada: Help!\n",
      "Oración decodificada: ¡Ayuda!\n",
      "\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "-\n",
      "Oración de entrada: Hide.\n",
      "Oración decodificada: Escóndete.\n",
      "\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 218ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 238ms/step\n",
      "-\n",
      "Oración de entrada: Jump!\n",
      "Oración decodificada: ¡Salta!\n",
      "\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "-\n",
      "Oración de entrada: Jump.\n",
      "Oración decodificada: Salto.\n",
      "\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 225ms/step\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "-\n",
      "Oración de entrada: Jump.\n",
      "Oración decodificada: Salto.\n",
      "\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 237ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "-\n",
      "Oración de entrada: Stay.\n",
      "Oración decodificada: Quédate.\n",
      "\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "-\n",
      "Oración de entrada: Stop!\n",
      "Oración decodificada: ¡Parad!\n",
      "\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "1/1 [==============================] - 0s 225ms/step\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 207ms/step\n",
      "-\n",
      "Oración de entrada: Stop!\n",
      "Oración decodificada: ¡Parad!\n",
      "\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "-\n",
      "Oración de entrada: Stop!\n",
      "Oración decodificada: ¡Parad!\n",
      "\n",
      "1/1 [==============================] - 0s 218ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "-\n",
      "Oración de entrada: Wait!\n",
      "Oración decodificada: ¡Espérate!\n",
      "\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 212ms/step\n",
      "-\n",
      "Oración de entrada: Wait!\n",
      "Oración decodificada: ¡Espérate!\n",
      "\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "1/1 [==============================] - 0s 229ms/step\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 242ms/step\n",
      "-\n",
      "Oración de entrada: Wait!\n",
      "Oración decodificada: ¡Espérate!\n",
      "\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 249ms/step\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "-\n",
      "Oración de entrada: Wait.\n",
      "Oración decodificada: Esperad.\n",
      "\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "-\n",
      "Oración de entrada: Wait.\n",
      "Oración decodificada: Esperad.\n",
      "\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 218ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "-\n",
      "Oración de entrada: Wait.\n",
      "Oración decodificada: Esperad.\n",
      "\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 229ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "-\n",
      "Oración de entrada: Begin.\n",
      "Oración decodificada: Empieza.\n",
      "\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "-\n",
      "Oración de entrada: Do it.\n",
      "Oración decodificada: Hacedlo.\n",
      "\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "-\n",
      "Oración de entrada: Go on.\n",
      "Oración decodificada: Continúe.\n",
      "\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "1/1 [==============================] - 0s 244ms/step\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "-\n",
      "Oración de entrada: Go on.\n",
      "Oración decodificada: Continúe.\n",
      "\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "-\n",
      "Oración de entrada: Hello!\n",
      "Oración decodificada: Hola.\n",
      "\n",
      "1/1 [==============================] - 0s 230ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "-\n",
      "Oración de entrada: Hello.\n",
      "Oración decodificada: Hola.\n",
      "\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "-\n",
      "Oración de entrada: Hurry!\n",
      "Oración decodificada: ¡Daos prisa!\n",
      "\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 242ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "-\n",
      "Oración de entrada: Hurry!\n",
      "Oración decodificada: ¡Daos prisa!\n",
      "\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 224ms/step\n",
      "1/1 [==============================] - 0s 244ms/step\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "-\n",
      "Oración de entrada: Hurry!\n",
      "Oración decodificada: ¡Daos prisa!\n",
      "\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 229ms/step\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "-\n",
      "Oración de entrada: I hid.\n",
      "Oración decodificada: Me escondí.\n",
      "\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "1/1 [==============================] - 0s 212ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "-\n",
      "Oración de entrada: I hid.\n",
      "Oración decodificada: Me escondí.\n",
      "\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "-\n",
      "Oración de entrada: I hid.\n",
      "Oración decodificada: Me escondí.\n",
      "\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 229ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 238ms/step\n",
      "1/1 [==============================] - 0s 230ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "-\n",
      "Oración de entrada: I hid.\n",
      "Oración decodificada: Me escondí.\n",
      "\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "-\n",
      "Oración de entrada: I ran.\n",
      "Oración decodificada: Corrí.\n",
      "\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "-\n",
      "Oración de entrada: I ran.\n",
      "Oración decodificada: Corrí.\n",
      "\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 225ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "-\n",
      "Oración de entrada: I try.\n",
      "Oración decodificada: Lo intento.\n",
      "\n",
      "1/1 [==============================] - 0s 212ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "-\n",
      "Oración de entrada: I won!\n",
      "Oración decodificada: ¡He ganado!\n",
      "\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 228ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "-\n",
      "Oración de entrada: I won!\n",
      "Oración decodificada: ¡He ganado!\n",
      "\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 212ms/step\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "-\n",
      "Oración de entrada: Oh no!\n",
      "Oración decodificada: ¡Oh, no!\n",
      "\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 237ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 224ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "-\n",
      "Oración de entrada: Relax.\n",
      "Oración decodificada: Tranquilo.\n",
      "\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 229ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "-\n",
      "Oración de entrada: Relax.\n",
      "Oración decodificada: Tranquilo.\n",
      "\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 238ms/step\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 225ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "-\n",
      "Oración de entrada: Shoot!\n",
      "Oración decodificada: ¡Disparad!\n",
      "\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 237ms/step\n",
      "-\n",
      "Oración de entrada: Shoot!\n",
      "Oración decodificada: ¡Disparad!\n",
      "\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 228ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "-\n",
      "Oración de entrada: Shoot!\n",
      "Oración decodificada: ¡Disparad!\n",
      "\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 238ms/step\n",
      "1/1 [==============================] - 0s 237ms/step\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 212ms/step\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "-\n",
      "Oración de entrada: Shoot!\n",
      "Oración decodificada: ¡Disparad!\n",
      "\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 225ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "1/1 [==============================] - 0s 228ms/step\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "-\n",
      "Oración de entrada: Shoot!\n",
      "Oración decodificada: ¡Disparad!\n",
      "\n",
      "1/1 [==============================] - 0s 207ms/step\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 218ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "-\n",
      "Oración de entrada: Shoot!\n",
      "Oración decodificada: ¡Disparad!\n",
      "\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "-\n",
      "Oración de entrada: Shoot!\n",
      "Oración decodificada: ¡Disparad!\n",
      "\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 249ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "-\n",
      "Oración de entrada: Smile.\n",
      "Oración decodificada: Sonríe.\n",
      "\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 218ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "-\n",
      "Oración de entrada: Sorry?\n",
      "Oración decodificada: ¿Disculpa?\n",
      "\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "-\n",
      "Oración de entrada: Attack!\n",
      "Oración decodificada: ¡Ataca!\n",
      "\n",
      "1/1 [==============================] - 0s 244ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 212ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "-\n",
      "Oración de entrada: Attack!\n",
      "Oración decodificada: ¡Ataca!\n",
      "\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "-\n",
      "Oración de entrada: Attack!\n",
      "Oración decodificada: ¡Ataca!\n",
      "\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 243ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 244ms/step\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 218ms/step\n",
      "-\n",
      "Oración de entrada: Attack!\n",
      "Oración decodificada: ¡Ataca!\n",
      "\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 242ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 230ms/step\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "-\n",
      "Oración de entrada: Attack!\n",
      "Oración decodificada: ¡Ataca!\n",
      "\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "-\n",
      "Oración de entrada: Buy it.\n",
      "Oración decodificada: Cómpralo.\n",
      "\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 244ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 224ms/step\n",
      "-\n",
      "Oración de entrada: Buy it.\n",
      "Oración decodificada: Cómpralo.\n",
      "\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 207ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 229ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "-\n",
      "Oración de entrada: Eat it.\n",
      "Oración decodificada: Cómanselo.\n",
      "\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 218ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 218ms/step\n",
      "-\n",
      "Oración de entrada: Eat it.\n",
      "Oración decodificada: Cómanselo.\n",
      "\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "-\n",
      "Oración de entrada: Eat it.\n",
      "Oración decodificada: Cómanselo.\n",
      "\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 237ms/step\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "-\n",
      "Oración de entrada: Eat it.\n",
      "Oración decodificada: Cómanselo.\n",
      "\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "-\n",
      "Oración de entrada: Get up.\n",
      "Oración decodificada: Levanta.\n",
      "\n",
      "1/1 [==============================] - 0s 207ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 225ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 212ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "-\n",
      "Oración de entrada: Go now.\n",
      "Oración decodificada: Ve ya.\n",
      "\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "-\n",
      "Oración de entrada: Go now.\n",
      "Oración decodificada: Ve ya.\n",
      "\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 207ms/step\n",
      "1/1 [==============================] - 0s 224ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "-\n",
      "Oración de entrada: Go now.\n",
      "Oración decodificada: Ve ya.\n",
      "\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "-\n",
      "Oración de entrada: Go now.\n",
      "Oración decodificada: Ve ya.\n",
      "\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 243ms/step\n",
      "1/1 [==============================] - 0s 243ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "-\n",
      "Oración de entrada: Go now.\n",
      "Oración decodificada: Ve ya.\n",
      "\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 218ms/step\n",
      "-\n",
      "Oración de entrada: Go now.\n",
      "Oración decodificada: Ve ya.\n",
      "\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "-\n",
      "Oración de entrada: Go now.\n",
      "Oración decodificada: Ve ya.\n",
      "\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 224ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "-\n",
      "Oración de entrada: Go now.\n",
      "Oración decodificada: Ve ya.\n",
      "\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "1/1 [==============================] - 0s 224ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "-\n",
      "Oración de entrada: Got it!\n",
      "Oración decodificada: ¡Lo tengo!\n",
      "\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "-\n",
      "Oración de entrada: Got it?\n",
      "Oración decodificada: ¿Lo pillas?\n",
      "\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 225ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "-\n",
      "Oración de entrada: Got it?\n",
      "Oración decodificada: ¿Lo pillas?\n",
      "\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "1/1 [==============================] - 0s 243ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "-\n",
      "Oración de entrada: He ran.\n",
      "Oración decodificada: Él corrió.\n",
      "\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 218ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "-\n",
      "Oración de entrada: He ran.\n",
      "Oración decodificada: Él corrió.\n",
      "\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 212ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 224ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "-\n",
      "Oración de entrada: Hop in.\n",
      "Oración decodificada: Métete adentro.\n",
      "\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 224ms/step\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "-\n",
      "Oración de entrada: Hug me.\n",
      "Oración decodificada: Abrázame.\n",
      "\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "-\n",
      "Oración de entrada: I care.\n",
      "Oración decodificada: Me preocupo.\n",
      "\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 225ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "-\n",
      "Oración de entrada: I fell.\n",
      "Oración decodificada: Me caí.\n",
      "\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 230ms/step\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "-\n",
      "Oración de entrada: I fled.\n",
      "Oración decodificada: Me escapabab.\n",
      "\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "-\n",
      "Oración de entrada: I fled.\n",
      "Oración decodificada: Me escapabab.\n",
      "\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "-\n",
      "Oración de entrada: I fled.\n",
      "Oración decodificada: Me escapabab.\n",
      "\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "-\n",
      "Oración de entrada: I fled.\n",
      "Oración decodificada: Me escapabab.\n",
      "\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "-\n",
      "Oración de entrada: I know.\n",
      "Oración decodificada: Yo lo sé.\n",
      "\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "-\n",
      "Oración de entrada: I know.\n",
      "Oración decodificada: Yo lo sé.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(\"-\")\n",
    "    print(\"Oración de entrada:\", input_texts[seq_index])\n",
    "    print(\"Oración decodificada:\", decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incluir 1 capa adicional de LSTM al encoder y decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "latent_dim = 256  # Adjust this according to your needs\n",
    "num_encoder_tokens = ...  # Define the number of encoder tokens\n",
    "num_decoder_tokens = ...  # Define the number of decoder tokens\n",
    "\n",
    "# Define input layers\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "\n",
    "# Encoder LSTM layers\n",
    "encoder_lstm_1 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "encoder_outputs_1, state_h_1, state_c_1 = encoder_lstm_1(encoder_inputs)\n",
    "\n",
    "encoder_lstm_2 = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm_2(encoder_outputs_1)\n",
    "\n",
    "# Decoder LSTM layers\n",
    "decoder_lstm_1 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs_1, _, _ = decoder_lstm_1(decoder_inputs, initial_state=[state_h, state_c])\n",
    "\n",
    "decoder_lstm_2 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm_2(decoder_outputs_1)\n",
    "\n",
    "# Dense layer for output\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "output = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], output)\n",
    "\n",
    "# Compile the model and specify the optimizer, loss, etc.\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
