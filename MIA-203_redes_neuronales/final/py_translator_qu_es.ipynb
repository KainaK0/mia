{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEmbeddings(nn.Module):\n",
    "    def __init__(self, d_model:int, vocabulary_size: int):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = vocabulary_size\n",
    "        self.embedding = nn.Embedding(vocabulary_size, d_model)\n",
    "    def forward(self,x):\n",
    "        return self.embedding(x) * math.sqrt(self.d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, sequence_len:int, dropout: float) -> None:\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.seq_len = sequence_len\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Create a matrix of shape (seq_len, d_model)\n",
    "        pe = torch.zeros(sequence_len, d_model)\n",
    "        # Create a vector of shape (seq_len)\n",
    "        position = torch.arange(0, sequence_len, dtype=torch.float).unsqueeze(1) # (seq_len, 1)\n",
    "        # Create a vector of shape (d_model)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)) # (d_model / 2)\n",
    "        # Apply sine to even indices\n",
    "        pe[:, 0::2] = torch.sin(position * div_term) # sin(position * (10000 ** (2i / d_model))\n",
    "        # Apply cosine to odd indices\n",
    "        pe[:, 1::2] = torch.cos(position * div_term) # cos(position * (10000 ** (2i / d_model))\n",
    "        # Add a batch dimension to the positional encoding\n",
    "        pe = pe.unsqueeze(0) # (1, seq_len, d_model)\n",
    "        # Register the positional encoding as a buffer\n",
    "        self.register_buffer('pe', pe)\n",
    "    def forward(self,x):\n",
    "        x = x + (self.pe[:, :x.shape[1], :]).requires_grad_(False) # (batch, seq_len, d_model)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(nn.Module):\n",
    "\n",
    "    def __init__(self, parameters_shape: int, eps:float=10**-6) -> None:\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.alpha = nn.Parameter(torch.ones(parameters_shape)) # alpha is a learnable parameter\n",
    "        self.bias = nn.Parameter(torch.zeros(parameters_shape)) # bias is a learnable parameter\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, hidden_size)\n",
    "         # Keep the dimension for broadcasting\n",
    "        mean = x.mean(dim = -1, keepdim = True) # (batch, seq_len, 1)\n",
    "        # Keep the dimension for broadcasting\n",
    "        std = x.std(dim = -1, keepdim = True) # (batch, seq_len, 1)\n",
    "        # eps is to prevent dividing by zero or when std is very small\n",
    "        return self.alpha * (x - mean) / (std + self.eps) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, d_ff: int, dropout: float = 0.1) -> None:\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff) # w1 and b1\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model) # w2 and b2\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (batch, seq_len, d_model) --> (batch, seq_len, d_ff) --> (batch, seq_len, d_model)\n",
    "        x = self.linear_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear_2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, h: int, dropout: float) -> None:\n",
    "        super().__init__()\n",
    "        self.d_model = d_model # Embedding vector size\n",
    "        self.h = h # Number of heads\n",
    "        # Make sure d_model is divisible by h\n",
    "        assert d_model % h == 0, \"d_model is not divisible by h\"\n",
    "\n",
    "        self.d_k = d_model // h # Dimension of vector seen by each head\n",
    "        self.w_q = nn.Linear(d_model, d_model, bias=False) # Wq\n",
    "        self.w_k = nn.Linear(d_model, d_model, bias=False) # Wk\n",
    "        self.w_v = nn.Linear(d_model, d_model, bias=False) # Wv\n",
    "        self.w_o = nn.Linear(d_model, d_model, bias=False) # Wo\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    @staticmethod\n",
    "    def attention(query, key, value, mask, dropout: nn.Dropout):\n",
    "        d_k = query.shape[-1]\n",
    "        # Just apply the formula from the paper\n",
    "        # (batch, h, seq_len, d_k) --> (batch, h, seq_len, seq_len)\n",
    "        attention_scores = (query @ key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "        if mask is not None:\n",
    "            # Write a very low value (indicating -inf) to the positions where mask == 0\n",
    "            attention_scores.masked_fill_(mask == 0, -1e9)\n",
    "        attention_scores = attention_scores.softmax(dim=-1) # (batch, h, seq_len, seq_len) # Apply softmax\n",
    "        if dropout is not None:\n",
    "            attention_scores = dropout(attention_scores)\n",
    "        # (batch, h, seq_len, seq_len) --> (batch, h, seq_len, d_k)\n",
    "        # return attention scores which can be used for visualization\n",
    "        return (attention_scores @ value), attention_scores\n",
    "\n",
    "    def forward(self, q, k, v, mask):\n",
    "        query = self.w_q(q) # (batch, seq_len, d_model) --> (batch, seq_len, d_model)\n",
    "        key = self.w_k(k) # (batch, seq_len, d_model) --> (batch, seq_len, d_model)\n",
    "        value = self.w_v(v) # (batch, seq_len, d_model) --> (batch, seq_len, d_model)\n",
    "\n",
    "        # (batch, seq_len, d_model) --> (batch, seq_len, h, d_k) --> (batch, h, seq_len, d_k)\n",
    "        query = query.view(query.shape[0], query.shape[1], self.h, self.d_k).transpose(1, 2)\n",
    "        key = key.view(key.shape[0], key.shape[1], self.h, self.d_k).transpose(1, 2)\n",
    "        value = value.view(value.shape[0], value.shape[1], self.h, self.d_k).transpose(1, 2)\n",
    "\n",
    "        # Calculate attention\n",
    "        x, self.attention_scores = MultiHeadAttentionBlock.attention(query, key, value, mask, self.dropout)\n",
    "        \n",
    "        # Combine all the heads together\n",
    "        # (batch, h, seq_len, d_k) --> (batch, seq_len, h, d_k) --> (batch, seq_len, d_model)\n",
    "        x = x.transpose(1, 2).contiguous().view(x.shape[0], -1, self.h * self.d_k)\n",
    "\n",
    "        # Multiply by Wo\n",
    "        # (batch, seq_len, d_model) --> (batch, seq_len, d_model)  \n",
    "        return self.w_o(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualConnection(nn.Module):\n",
    "    \n",
    "        def __init__(self, features: int, dropout: float) -> None:\n",
    "            super().__init__()\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "            self.norm = LayerNormalization(features)\n",
    "    \n",
    "        def forward(self, x, sublayer):\n",
    "            x = self.norm(x)\n",
    "            x = self.dropout(sublayer(x)) + x\n",
    "            return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, features: int, self_attention_block: MultiHeadAttentionBlock, feed_forward_block: FeedForwardBlock, dropout: float) -> None:\n",
    "        super().__init__()\n",
    "        self.self_attention_block = self_attention_block\n",
    "        self.feed_forward_block = feed_forward_block\n",
    "        self.residual_connections = nn.ModuleList([ResidualConnection(features, dropout) for _ in range(2)])\n",
    "\n",
    "    def forward(self, x, src_mask):\n",
    "        x = self.residual_connections[0](x, lambda x: self.self_attention_block(x, x, x, src_mask))\n",
    "        x = self.residual_connections[1](x, self.feed_forward_block)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, features: int, layers: nn.ModuleList) -> None:\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        self.norm = LayerNormalization(features)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, features: int, self_attention_block: MultiHeadAttentionBlock, cross_attention_block: MultiHeadAttentionBlock, feed_forward_block: FeedForwardBlock, dropout: float) -> None:\n",
    "        super().__init__()\n",
    "        self.self_attention_block = self_attention_block\n",
    "        self.cross_attention_block = cross_attention_block\n",
    "        self.feed_forward_block = feed_forward_block\n",
    "        self.residual_connections = nn.ModuleList([ResidualConnection(features, dropout) for _ in range(3)])\n",
    "\n",
    "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
    "        x = self.residual_connections[0](x, lambda x: self.self_attention_block(x, x, x, tgt_mask))\n",
    "        x = self.residual_connections[1](x, lambda x: self.cross_attention_block(x, encoder_output, encoder_output, src_mask))\n",
    "        x = self.residual_connections[2](x, self.feed_forward_block)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, features: int, layers: nn.ModuleList) -> None:\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        self.norm = LayerNormalization(features)\n",
    "\n",
    "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, encoder_output, src_mask, tgt_mask)\n",
    "        return self.norm(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectionLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, vocab_size) -> None:\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x) -> None:\n",
    "        # (batch, seq_len, d_model) --> (batch, seq_len, vocab_size)\n",
    "        return self.proj(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, encoder: Encoder, decoder: Decoder, src_embed: InputEmbeddings, tgt_embed: InputEmbeddings, src_pos: PositionalEncoding, tgt_pos: PositionalEncoding, projection_layer: ProjectionLayer) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.src_pos = src_pos\n",
    "        self.tgt_pos = tgt_pos\n",
    "        self.projection_layer = projection_layer\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        # (batch, seq_len, d_model)\n",
    "        src = self.src_embed(src)\n",
    "        src = self.src_pos(src)\n",
    "        return self.encoder(src, src_mask)\n",
    "    \n",
    "    def decode(self, encoder_output: torch.Tensor, src_mask: torch.Tensor, tgt: torch.Tensor, tgt_mask: torch.Tensor):\n",
    "        # (batch, seq_len, d_model)\n",
    "        tgt = self.tgt_embed(tgt)\n",
    "        tgt = self.tgt_pos(tgt)\n",
    "        return self.decoder(tgt, encoder_output, src_mask, tgt_mask)\n",
    "    \n",
    "    def project(self, x):\n",
    "        # (batch, seq_len, vocab_size)\n",
    "        return self.projection_layer(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transformer(src_vocab_size: int, tgt_vocab_size: int, src_seq_len: int, tgt_seq_len: int, d_model: int=512, N_layers: int=6, h: int=8, dropout: float=0.1, d_ff: int=2048) -> Transformer:\n",
    "    # Create the embedding layers\n",
    "    src_embed = InputEmbeddings(d_model, src_vocab_size)\n",
    "    tgt_embed = InputEmbeddings(d_model, tgt_vocab_size)\n",
    "\n",
    "    # Create the positional encoding layers\n",
    "    src_pos = PositionalEncoding(d_model, src_seq_len, dropout)\n",
    "    tgt_pos = PositionalEncoding(d_model, tgt_seq_len, dropout)\n",
    "    \n",
    "    # Create the encoder blocks\n",
    "    encoder_blocks = []\n",
    "    for _ in range(N_layers):\n",
    "        encoder_self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n",
    "        feed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\n",
    "        encoder_block = EncoderBlock(d_model, encoder_self_attention_block, feed_forward_block, dropout)\n",
    "        encoder_blocks.append(encoder_block)\n",
    "\n",
    "    # Create the decoder blocks\n",
    "    decoder_blocks = []\n",
    "    for _ in range(N_layers):\n",
    "        decoder_self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n",
    "        decoder_cross_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n",
    "        feed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\n",
    "        decoder_block = DecoderBlock(d_model, decoder_self_attention_block, decoder_cross_attention_block, feed_forward_block, dropout)\n",
    "        decoder_blocks.append(decoder_block)\n",
    "    \n",
    "    # Create the encoder and decoder\n",
    "    encoder = Encoder(d_model, nn.ModuleList(encoder_blocks))\n",
    "    decoder = Decoder(d_model, nn.ModuleList(decoder_blocks))\n",
    "    \n",
    "    # Create the projection layer\n",
    "    projection_layer = ProjectionLayer(d_model, tgt_vocab_size)\n",
    "    \n",
    "    # Create the transformer\n",
    "    transformer = Transformer(encoder, decoder, src_embed, tgt_embed, src_pos, tgt_pos, projection_layer)\n",
    "    \n",
    "    # Initialize the parameters\n",
    "    for p in transformer.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    \n",
    "    return transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kainak0\\Documents\\gitProjects\\mia\\MIA-203_redes_neuronales\\final\\translatepy\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# from model import build_transformer\n",
    "# from dataset import BilingualDataset, causal_mask\n",
    "# from config import get_config, get_weights_file_path\n",
    "\n",
    "# import torchtext.datasets as datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Huggingface datasets and tokenizers\n",
    "from datasets import load_dataset\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import wandb\n",
    "\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_raw = load_dataset(f\"somosnlp-hackathon-2022/spanish-to-quechua\", split='train')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['es', 'qu'],\n",
       "    num_rows: 102747\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config():\n",
    "    return {\n",
    "        \"batch_size\": 56,\n",
    "        \"num_epochs\": 20,\n",
    "        \"lr\": 10**-4,\n",
    "        \"seq_len\": 200,\n",
    "        \"d_model\": 512,\n",
    "        'N_layers': 4,\n",
    "        'heads': 8,\n",
    "        'dropout': 0.1,\n",
    "        'ffn_hidden': 2048,\n",
    "        \"datasource\": 'spanish-to-quechua',\n",
    "        \"lang_src\": \"es\",\n",
    "        \"lang_tgt\": \"qu\",\n",
    "        \"model_folder\": \"weights\",\n",
    "        \"model_basename\": \"tmodel_\",\n",
    "        \"preload\": \"latest\",\n",
    "        \"tokenizer_file\": \"tokenizer_{0}.json\",\n",
    "        \"experiment_name\": \"runs/tmodel\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the latest weights file in the weights folder\n",
    "def latest_weights_file_path(config):\n",
    "    model_folder = f\"{config['datasource']}_{config['model_folder']}\"\n",
    "    model_filename = f\"{config['model_basename']}*\"\n",
    "    weights_files = list(Path(model_folder).glob(model_filename))\n",
    "    if len(weights_files) == 0:\n",
    "        return None\n",
    "    weights_files.sort()\n",
    "    return str(weights_files[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights_file_path(config, epoch: str):\n",
    "    model_folder = f\"{config['datasource']}_{config['model_folder']}\"\n",
    "    model_filename = f\"{config['model_basename']}{epoch}.pt\"\n",
    "    return str(Path('.') / model_folder / model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def hist_len_sentence(ds_raw, lang, min_sentence_len, max_sentence_len):\n",
    "    len_sentence = [len(x) for x in ds_raw[lang]]\n",
    "    len_sentence_ranged = [x for x in len_sentence if min_sentence_len < x < max_sentence_len]\n",
    "\n",
    "    # Generate sample data\n",
    "    data = np.array(len_sentence_ranged)\n",
    "\n",
    "    # Create the figure and axis\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot histogram\n",
    "    plt.hist(data, bins=30, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.title('Normal Distribution Histogram', fontsize=14)\n",
    "    plt.xlabel('Value', fontsize=12)\n",
    "    plt.ylabel('Frequency', fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(np.arange(0, max_sentence_len, 20))\n",
    "    # Add some padding to the layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist_len_sentence(ds_raw, lang = config['lang_src'], min_sentence_len = 0, max_sentence_len = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_length(dataset, min_len=1, max_len=1000):\n",
    "    def length_filter(example):\n",
    "        # Check length for all string/list features\n",
    "        for key, value in example.items():\n",
    "            if isinstance(value, (str, list)):\n",
    "                if len(value) < min_len or len(value) > max_len:\n",
    "                    return False\n",
    "        return True\n",
    "    \n",
    "    filtered_dataset = dataset.filter(length_filter)\n",
    "    return filtered_dataset\n",
    "\n",
    "# Usage example:\n",
    "filtered_ds_raw = filter_by_length(ds_raw, min_len=20, max_len=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['es', 'qu'],\n",
       "    num_rows: 89047\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_ds_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_sentences(ds, lang):\n",
    "    for item in ds:\n",
    "        yield item[lang]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_build_tokenizer(ds, lang):\n",
    "    tokenizer_path = Path(\"tokenizer_{0}.json\".format(lang))\n",
    "    # if not Path.exists(tokenizer_path):\n",
    "    if True:\n",
    "        # Most code taken from: https://huggingface.co/docs/tokenizers/quicktour\n",
    "        tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "        tokenizer.pre_tokenizer = Whitespace()\n",
    "        trainer = WordLevelTrainer(special_tokens=[\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\"], min_frequency=2)\n",
    "        tokenizer.train_from_iterator(get_all_sentences(ds, lang), trainer=trainer)\n",
    "        tokenizer.save(str(tokenizer_path))\n",
    "    else:\n",
    "        tokenizer = Tokenizer.from_file(str(tokenizer_path))\n",
    "    return tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class BilingualDataset(Dataset):\n",
    "\n",
    "    def __init__(self, ds, tokenizer_src, tokenizer_tgt, src_lang, tgt_lang, seq_len):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        self.ds = ds\n",
    "        self.tokenizer_src = tokenizer_src\n",
    "        self.tokenizer_tgt = tokenizer_tgt\n",
    "        self.src_lang = src_lang\n",
    "        self.tgt_lang = tgt_lang\n",
    "\n",
    "        self.sos_token = torch.tensor([tokenizer_tgt.token_to_id(\"[SOS]\")], dtype=torch.int64)\n",
    "        self.eos_token = torch.tensor([tokenizer_tgt.token_to_id(\"[EOS]\")], dtype=torch.int64)\n",
    "        self.pad_token = torch.tensor([tokenizer_tgt.token_to_id(\"[PAD]\")], dtype=torch.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_target_pair = self.ds[idx]\n",
    "        src_text = src_target_pair[self.src_lang]\n",
    "        tgt_text = src_target_pair[self.tgt_lang]\n",
    "\n",
    "        # Transform the text into tokens\n",
    "        enc_input_tokens = self.tokenizer_src.encode(src_text).ids\n",
    "        dec_input_tokens = self.tokenizer_tgt.encode(tgt_text).ids\n",
    "\n",
    "        # Add sos, eos and padding to each sentence\n",
    "        enc_num_padding_tokens = self.seq_len - len(enc_input_tokens) - 2  # We will add <s> and </s>\n",
    "        # We will only add <s>, and </s> only on the label\n",
    "        dec_num_padding_tokens = self.seq_len - len(dec_input_tokens) - 1\n",
    "\n",
    "        # Make sure the number of padding tokens is not negative. If it is, the sentence is too long\n",
    "        if enc_num_padding_tokens < 0 or dec_num_padding_tokens < 0:\n",
    "            raise ValueError(\"Sentence is too long\")\n",
    "        # Add <s> and </s> token\n",
    "        encoder_input = torch.cat(\n",
    "            [\n",
    "                self.sos_token,\n",
    "                torch.tensor(enc_input_tokens, dtype=torch.int64),\n",
    "                self.eos_token,\n",
    "                torch.tensor([self.pad_token] * enc_num_padding_tokens, dtype=torch.int64),\n",
    "            ],\n",
    "            dim=0,\n",
    "        )\n",
    "        # Add only <s> token\n",
    "        decoder_input = torch.cat(\n",
    "            [\n",
    "                self.sos_token,\n",
    "                torch.tensor(dec_input_tokens, dtype=torch.int64),\n",
    "                torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype=torch.int64),\n",
    "            ],\n",
    "            dim=0,\n",
    "        )\n",
    "        # Add only </s> token\n",
    "        label = torch.cat(\n",
    "            [\n",
    "                torch.tensor(dec_input_tokens, dtype=torch.int64),\n",
    "                self.eos_token,\n",
    "                torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype=torch.int64),\n",
    "            ],\n",
    "            dim=0,\n",
    "        )\n",
    "        # Double check the size of the tensors to make sure they are all seq_len long\n",
    "        assert encoder_input.size(0) == self.seq_len\n",
    "        assert decoder_input.size(0) == self.seq_len\n",
    "        assert label.size(0) == self.seq_len\n",
    "\n",
    "        return {\n",
    "            \"encoder_input\": encoder_input,  # (seq_len)\n",
    "            \"decoder_input\": decoder_input,  # (seq_len)\n",
    "            \"encoder_mask\": (encoder_input != self.pad_token).unsqueeze(0).unsqueeze(0).int(), # (1, 1, seq_len)\n",
    "            \"decoder_mask\": (decoder_input != self.pad_token).unsqueeze(0).int() & causal_mask(decoder_input.size(0)), # (1, seq_len) & (1, seq_len, seq_len),\n",
    "            \"label\": label,  # (seq_len)\n",
    "            \"src_text\": src_text,\n",
    "            \"tgt_text\": tgt_text,\n",
    "        }\n",
    "    \n",
    "def causal_mask(size):\n",
    "    mask = torch.triu(torch.ones((1, size, size)), diagonal=1).type(torch.int)\n",
    "    return mask == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, source, source_mask, tokenizer_src, tokenizer_tgt, max_len, device):\n",
    "    sos_idx = tokenizer_tgt.token_to_id('[SOS]')\n",
    "    eos_idx = tokenizer_tgt.token_to_id('[EOS]')\n",
    "\n",
    "    # Precompute the encoder output and reuse it for every step\n",
    "    encoder_output = model.encode(source, source_mask)\n",
    "    # Initialize the decoder input with the sos token\n",
    "    decoder_input = torch.empty(1, 1).fill_(sos_idx).type_as(source).to(device)\n",
    "    while True:\n",
    "        if decoder_input.size(1) == max_len:\n",
    "            break\n",
    "\n",
    "        # build mask for target\n",
    "        decoder_mask = causal_mask(decoder_input.size(1)).type_as(source_mask).to(device)\n",
    "\n",
    "        # calculate output\n",
    "        out = model.decode(encoder_output, source_mask, decoder_input, decoder_mask)\n",
    "\n",
    "        # get next token\n",
    "        prob = model.project(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        decoder_input = torch.cat(\n",
    "            [decoder_input, torch.empty(1, 1).type_as(source).fill_(next_word.item()).to(device)], dim=1\n",
    "        )\n",
    "\n",
    "        if next_word == eos_idx:\n",
    "            break\n",
    "\n",
    "    return decoder_input.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_validation(model, validation_ds, tokenizer_src, tokenizer_tgt, max_len, device, print_msg, global_step, writer, num_examples=2):\n",
    "    model.eval()\n",
    "    count = 0\n",
    "\n",
    "    source_texts = []\n",
    "    expected = []\n",
    "    predicted = []\n",
    "\n",
    "    try:\n",
    "        # get the console window width\n",
    "        with os.popen('stty size', 'r') as console:\n",
    "            _, console_width = console.read().split()\n",
    "            console_width = int(console_width)\n",
    "    except:\n",
    "        # If we can't get the console width, use 80 as default\n",
    "        console_width = 80\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in validation_ds:\n",
    "            count += 1\n",
    "            encoder_input = batch[\"encoder_input\"].to(device) # (b, seq_len)\n",
    "            encoder_mask = batch[\"encoder_mask\"].to(device) # (b, 1, 1, seq_len)\n",
    "\n",
    "            # check that the batch size is 1\n",
    "            assert encoder_input.size(\n",
    "                0) == 1, \"Batch size must be 1 for validation\"\n",
    "\n",
    "            model_out = greedy_decode(model, encoder_input, encoder_mask, tokenizer_src, tokenizer_tgt, max_len, device)\n",
    "\n",
    "            source_text = batch[\"src_text\"][0]\n",
    "            target_text = batch[\"tgt_text\"][0]\n",
    "            model_out_text = tokenizer_tgt.decode(model_out.detach().cpu().numpy())\n",
    "\n",
    "            source_texts.append(source_text)\n",
    "            expected.append(target_text)\n",
    "            predicted.append(model_out_text)\n",
    "            \n",
    "            # Print the source, target and model output\n",
    "            print_msg('-'*console_width)\n",
    "            print_msg(f\"{f'SOURCE: ':>12}{source_text}\")\n",
    "            print_msg(f\"{f'TARGET: ':>12}{target_text}\")\n",
    "            print_msg(f\"{f'PREDICTED: ':>12}{model_out_text}\")\n",
    "\n",
    "            if count == num_examples:\n",
    "                print_msg('-'*console_width)\n",
    "                break\n",
    "    \n",
    "    if writer:\n",
    "        # Evaluate the character error rate\n",
    "        # Compute the char error rate \n",
    "        metric = torchmetrics.CharErrorRate()\n",
    "        cer = metric(predicted, expected)\n",
    "        writer.add_scalar('validation cer', cer, global_step)\n",
    "        writer.flush()\n",
    "\n",
    "        # Compute the word error rate\n",
    "        metric = torchmetrics.WordErrorRate()\n",
    "        wer = metric(predicted, expected)\n",
    "        writer.add_scalar('validation wer', wer, global_step)\n",
    "        writer.flush()\n",
    "\n",
    "        # Compute the BLEU metric\n",
    "        metric = torchmetrics.BLEUScore()\n",
    "        bleu = metric(predicted, expected)\n",
    "        writer.add_scalar('validation BLEU', bleu, global_step)\n",
    "        writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_tgt = get_or_build_tokenizer( filtered_ds_raw, config['lang_tgt'])\n",
    "tokenizer_src =  get_or_build_tokenizer( filtered_ds_raw, config['lang_src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_size = int(0.9 * len(filtered_ds_raw))\n",
    "val_ds_size = len(filtered_ds_raw) - train_ds_size\n",
    "train_ds_raw, val_ds_raw = random_split(filtered_ds_raw, [train_ds_size, val_ds_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = BilingualDataset(train_ds_raw, tokenizer_src, tokenizer_tgt, src_lang = config['lang_src'],tgt_lang = config['lang_tgt'], seq_len = 200)\n",
    "val_ds = BilingualDataset(val_ds_raw, tokenizer_src, tokenizer_tgt, src_lang = config['lang_src'],tgt_lang = config['lang_tgt'], seq_len = 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True)\n",
    "val_dataloader = DataLoader(val_ds, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(config, vocab_src_len, vocab_tgt_len):\n",
    "    model = build_transformer(vocab_src_len, vocab_tgt_len, config[\"seq_len\"], config['seq_len'], d_model=config['d_model'],\n",
    "        N_layers=config['N_layers'], h = config['heads'], dropout = config['dropout'], d_ff = config['ffn_hidden'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config,train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt ):\n",
    "    # Define the device\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.has_mps or torch.backends.mps.is_available() else \"cpu\"\n",
    "    print(\"Using device:\", device)\n",
    "    if (device == 'cuda'):\n",
    "        print(f\"Device name: {torch.cuda.get_device_name(device.index)}\")\n",
    "        print(f\"Device memory: {torch.cuda.get_device_properties(device.index).total_memory / 1024 ** 3} GB\")\n",
    "    elif (device == 'mps'):\n",
    "        print(f\"Device name: <mps>\")\n",
    "    else:\n",
    "        print(\"plz bu a gpu :)\")\n",
    "     \n",
    "    # Make sure the weights folder exists\n",
    "    Path(f\"{config['datasource']}_{config['model_folder']}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    model = get_model(config, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()).to(device)\n",
    "    # Tensorboard\n",
    "    writer = SummaryWriter(config['experiment_name'])\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], eps=1e-9)\n",
    "\n",
    "    # If the user specified a model to preload before training, load it\n",
    "    initial_epoch = 0\n",
    "    global_step = 0\n",
    "    preload = config['preload']\n",
    "    model_filename = latest_weights_file_path(config) if preload == 'latest' else get_weights_file_path(config, preload) if preload else None\n",
    "    if model_filename:\n",
    "    # if False:\n",
    "        print(f'Preloading model {model_filename}')\n",
    "        state = torch.load(model_filename)\n",
    "        model.load_state_dict(state['model_state_dict'])\n",
    "        initial_epoch = state['epoch'] + 1\n",
    "        optimizer.load_state_dict(state['optimizer_state_dict'])\n",
    "        global_step = state['global_step']\n",
    "    else:\n",
    "        print('No model to preload, starting from scratch')\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer_src.token_to_id('[PAD]'), label_smoothing=0.1).to(device)\n",
    "\n",
    "    for epoch in range(initial_epoch, config['num_epochs']):\n",
    "        torch.cuda.empty_cache()\n",
    "        model.train()\n",
    "        batch_iterator = tqdm(train_dataloader, desc=f\"Processing Epoch {epoch:02d}\")\n",
    "        for batch in batch_iterator:\n",
    "\n",
    "            encoder_input = batch['encoder_input'].to(device) # (b, seq_len)\n",
    "            decoder_input = batch['decoder_input'].to(device) # (B, seq_len)\n",
    "            encoder_mask = batch['encoder_mask'].to(device) # (B, 1, 1, seq_len)\n",
    "            decoder_mask = batch['decoder_mask'].to(device) # (B, 1, seq_len, seq_len)\n",
    "\n",
    "            # Run the tensors through the encoder, decoder and the projection layer\n",
    "            encoder_output = model.encode(encoder_input, encoder_mask) # (B, seq_len, d_model)\n",
    "            decoder_output = model.decode(encoder_output, encoder_mask, decoder_input, decoder_mask) # (B, seq_len, d_model)\n",
    "            proj_output = model.project(decoder_output) # (B, seq_len, vocab_size)\n",
    "\n",
    "            # Compare the output with the label\n",
    "            label = batch['label'].to(device) # (B, seq_len)\n",
    "\n",
    "            # Compute the loss using a simple cross entropy\n",
    "            loss = loss_fn(proj_output.view(-1, tokenizer_tgt.get_vocab_size()), label.view(-1))\n",
    "            batch_iterator.set_postfix({\"loss\": f\"{loss.item():6.3f}\"})\n",
    "\n",
    "            # Log the loss\n",
    "            writer.add_scalar('train loss', loss.item(), global_step)\n",
    "            writer.flush()\n",
    "\n",
    "            # Backpropagate the loss\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            global_step += 1\n",
    "\n",
    "        # Run validation at the end of every epoch\n",
    "        run_validation(model, val_dataloader, tokenizer_src, tokenizer_tgt, config['seq_len'], device, lambda msg: batch_iterator.write(msg), global_step, writer)\n",
    "\n",
    "        # Save the model at the end of every epoch\n",
    "        model_filename = get_weights_file_path(config, f\"{epoch:02d}\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'global_step': global_step\n",
    "        }, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Device name: NVIDIA GeForce RTX 3090\n",
      "Device memory: 23.99951171875 GB\n",
      "No model to preload, starting from scratch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 00: 100%|| 1432/1432 [12:06<00:00,  1.97it/s, loss=7.201]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: l ve nuestras cualidades, as como vio las cualidades de los cuatro reyes de Jud.\n",
      "    TARGET: Payqa chay tawa kamachiqkunapa imayna kasqankuta qawasqanman hinam, uqanchikpa imayna kasqanchiktapas qawanqa.\n",
      " PREDICTED: \n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: La mayora de los adultos necesitan ocho horas de sueo por noche para recuperarse fsica, emocional y mentalmente.\n",
      "    TARGET: Yuyayniyoq runakunaqa yaqa llapankum 8 horata sapa tuta puunanku, chaymi yanapanqa cuerponkupi chaynataq piensayninkupi allinlla tarikunankupaq.\n",
      " PREDICTED: \n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 01:  50%|     | 720/1432 [06:05<05:59,  1.98it/s, loss=7.209]"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    config = get_config()\n",
    "    train_model(config,train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "translatepy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
